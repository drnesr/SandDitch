{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the rest of HYDRUS files [Stage 2]\n",
    "![The project files](../Assets/Project_files_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:11:24.343666Z",
     "start_time": "2019-11-27T10:11:21.168158Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from NesrHydrusAnalyst import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:11:24.362616Z",
     "start_time": "2019-11-27T10:11:24.359624Z"
    }
   },
   "outputs": [],
   "source": [
    "src = '../Datasets/H3D2_SandDitch0011'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unreadable files\n",
    "Encrypted files that are converted to text elswhere\n",
    "1. `h.out`\n",
    "2. `Q.out`\n",
    "3. `v.out`\n",
    "3. `th.out`\n",
    "4. `MESHTRIA.000`\n",
    "4. `DOMAIN.IN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading previous implemented files\n",
    "### Reading the _mesh files_\n",
    "1. `H.TXT`\n",
    "2. `V.TXT`\n",
    "3. `TH.TXT`\n",
    "4. `MESHTRIA.TXT`\n",
    "### Spread-info files\n",
    "\n",
    "1. `Cum_Q.out`\n",
    "1. `h_Mean.out`\n",
    "1. `v_Mean.out`\n",
    "5. `Run_Inf.out`\n",
    "### the _information files_\n",
    "1. `A_Level.out`\n",
    "2. `ATMOSPH.IN`\n",
    "3. `Balance.out`\n",
    "4. `DIMENSIO.IN`\n",
    "5. `Run_Inf.out` (Repeated)\n",
    "6. `SELECTOR.IN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files to be implemented here\n",
    "\n",
    "\n",
    "### Flux-info files\n",
    "\n",
    "1. `Boundary.out`\n",
    "1. `BOUNDARY.IN`\n",
    "1. `Check.out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:14:57.600491Z",
     "start_time": "2019-11-27T10:14:57.589520Z"
    }
   },
   "outputs": [],
   "source": [
    "folder =src\n",
    "\n",
    "# def read_boundary_data(folder='Current', save_to_csv=True,\n",
    "#                      read_velocities=False):\n",
    "#     '''\n",
    "#     A function to read both Theat and H files from HYDRUS outputs, \n",
    "#         then to:\n",
    "#             1- return one dataframe contains both data in a decent format.\n",
    "#             2- save this output to a CSV file (optional, True by default)\n",
    "#     Input:\n",
    "#         The name of the main folder (leave balank for the current folder)\n",
    "#         The option to save_to csv, default =True (Boolean)\n",
    "#     '''\n",
    "\n",
    "# Specify the source folder\n",
    "if folder == 'Current':\n",
    "    read_dir = os.getcwd()\n",
    "else:\n",
    "    read_dir = folder\n",
    "\n",
    "\n",
    "\n",
    "# Finding number of nodes in the file\n",
    "mesh_file = os.path.join(read_dir, 'BOUNDARY.IN')\n",
    "# num_cells = np.array(linecache.getline(mesh_file, 6).split(), int)#[0]\n",
    "linecache.getline(mesh_file, 6).split()\n",
    "# # Define dataframe titles\n",
    "# titles = ['n', 'x', 'y', 'z']\n",
    "# # Define a list of coordinates\n",
    "# full_data = [[0, 0, 0, 0]]\n",
    "# # Set a loop to geather all coordinates from MESHTRIA.TXT file\n",
    "# for i in range(8, num_cells + 8):\n",
    "#     full_data.append(\n",
    "#         np.array(linecache.getline(mesh_file, i).split(), float))\n",
    "# # Convert the list to numpy array then to a dataframe\n",
    "# coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:32:18.731709Z",
     "start_time": "2019-11-27T11:32:18.716750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>surface_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.040982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.762819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.275030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.512820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>3152</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3153</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>3154</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>3155</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>3156</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n  surface_area\n",
       "0       1      0.020491\n",
       "1       8      0.040982\n",
       "2       9      0.762819\n",
       "3      11      1.275030\n",
       "4      12      0.512820\n",
       "..    ...           ...\n",
       "513  3152      1.538460\n",
       "514  3153      1.538460\n",
       "515  3154      1.538460\n",
       "516  3155      1.538460\n",
       "517  3156      1.538460\n",
       "\n",
       "[518 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = src\n",
    "\n",
    "# def read_boundary_data(folder='Current', save_to_csv=True,\n",
    "#                      read_velocities=False):\n",
    "#     '''\n",
    "#     A function to read both Theat and H files from HYDRUS outputs,\n",
    "#         then to:\n",
    "#             1- return one dataframe contains both data in a decent format.\n",
    "#             2- save this output to a CSV file (optional, True by default)\n",
    "#     Input:\n",
    "#         The name of the main folder (leave balank for the current folder)\n",
    "#         The option to save_to csv, default =True (Boolean)\n",
    "#     '''\n",
    "\n",
    "# Specify the source folder\n",
    "if folder == 'Current':\n",
    "    read_dir = os.getcwd()\n",
    "else:\n",
    "    read_dir = folder\n",
    "\n",
    "# Finding number of nodes in the file\n",
    "mesh_file = os.path.join(read_dir, 'BOUNDARY.IN')\n",
    "num_cells = int(linecache.getline(mesh_file, 4).split()[0])\n",
    "# Define dataframe titles\n",
    "titles = ['n', 'surface_area']\n",
    "\n",
    "\n",
    "def get_num_lines(num_cells, nums_per_line=10):\n",
    "    num_lines = int(num_cells / nums_per_line)\n",
    "    if num_cells % nums_per_line > 0: num_lines += 1\n",
    "    return num_lines\n",
    "\n",
    "\n",
    "def read_snakey_list(file_name, start_line, end_line, data_type=float):\n",
    "    '''\n",
    "    Reading a list of numbers thar are stored in a text file, where\n",
    "    there are `numbers_count` numbers, stored as `nums_per_line` numbers \n",
    "    per line, the starting position of first occurence of numbers is at\n",
    "    `start_line` line number\n",
    "    returns a numpy array of the data with the `data_type` given\n",
    "    '''\n",
    "    points = []\n",
    "    for i in range(start_line, end_line):\n",
    "        points.extend(linecache.getline(file_name, i).split())\n",
    "    return np.array(points, data_type)\n",
    "\n",
    "\n",
    "num_lines = get_num_lines(num_cells, nums_per_line)\n",
    "\n",
    "first_line = 10\n",
    "end_line = first_line + num_lines\n",
    "points = read_snakey_list(mesh_file, first_line, end_line, data_type=int)\n",
    "\n",
    "first_line = end_line + 1\n",
    "end_line = first_line + num_lines\n",
    "areas = read_snakey_list(mesh_file, first_line, end_line)\n",
    "data = np.array([points, areas]).T\n",
    "data_in = pd.DataFrame(\n",
    "    data, columns=titles).astype({\n",
    "        \"n\": int,\n",
    "        \"surface_area\": float\n",
    "    })\n",
    "data_in\n",
    "# pd.DataFrame([points, areas], index=titles).T\n",
    "#     num_lines , start_line, num_lines + start_line, points\n",
    "#     points.append(np.array(linecache.getline(mesh_file, i).split(), int))\n",
    "# # Convert the list to numpy array then to a dataframe\n",
    "# coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)\n",
    "\n",
    "#     # Print head and tail of the dataframe to ensure correctness\n",
    "#     # pd.concat([coordinates_df.head(),coordinates_df.tail()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:14:57.600491Z",
     "start_time": "2019-11-27T10:14:57.589520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     # -----------------------------#\n",
    "#     # To get data from all files   #\n",
    "#     # -----------------------------#\n",
    "#     def get_data_from_file(filename='TH.TXT', main_caption='Theta'):\n",
    "#         '''\n",
    "#         Function to combine all values of a property to a single dataframe \n",
    "#         inputs:\n",
    "#         filename, the name of the file\n",
    "#         caption, the leading caption of the columns (we will add the portion '_T= xxx')\n",
    "#         where xxx is the timestep\n",
    "#         '''\n",
    "#         # compute number of lines for each timestep\n",
    "#         num_lines = int(math.ceil(num_cells / 10.))\n",
    "#         time_steps_remaining = True  # Flag to see if the loop should continue or not.\n",
    "#         times_df = pd.DataFrame([])  # Empty dataframe\n",
    "#         time_loc_start = 2  # The starting cell of the timestep\n",
    "#         # Check if it is a velocity file\n",
    "#         processing_velocity = (filename[-5:] == 'V.TXT')\n",
    "#         while time_steps_remaining:\n",
    "#             line_t = linecache.getline(filename, time_loc_start).split()\n",
    "#             # Check if it is the start of the timestep, otherwise exit\n",
    "#             if line_t[0] == 'Time':\n",
    "#                 t = int(line_t[2])\n",
    "#                 if processing_velocity:\n",
    "#                     velocity_component = {\n",
    "#                         'first': '1',\n",
    "#                         'second': '2',\n",
    "#                         'third': '3'\n",
    "#                     }[line_t[5].strip()]\n",
    "#                     caption = main_caption + velocity_component\n",
    "#                 else:\n",
    "#                     caption = main_caption\n",
    "#                 # Finding the last line of the timestep\n",
    "#                 tim_loc_end = num_lines + time_loc_start + 2\n",
    "#                 # The starting time is always 0 because steps starts in 1 in HYDRUS\n",
    "#                 time_data = [0]\n",
    "#                 # Create the timestep as one long list\n",
    "#                 for i in range(time_loc_start + 2, tim_loc_end):\n",
    "#                     time_data.extend(linecache.getline(filename, i).split())\n",
    "#                 # Convert the list to DataFrame\n",
    "#                 dft = pd.DataFrame(\n",
    "#                     np.array(time_data, float),\n",
    "#                     columns=['{}_T{}'.format(caption, t)])\n",
    "#                 if len(times_df) == 0:  # If it is the first timestep\n",
    "#                     times_df = dft.copy()\n",
    "#                 else:  # Otherwise (for all other timesteps)\n",
    "#                     times_df = pd.concat([times_df, dft], axis=1)\n",
    "#                 # Change the start to the probable next timestem (if exist)\n",
    "#                 time_loc_start = tim_loc_end + 1\n",
    "#                 time_steps_remaining = True if len(\n",
    "#                     linecache.getline(filename, time_loc_start)) > 0 else False\n",
    "#                 # End IF\n",
    "#         return times_df\n",
    "\n",
    "#     # Set the basic dataframe to the coordinates dataframe, to append to it.\n",
    "#     full_df = coordinates_df\n",
    "#     # Looping through the basic output files then to concatenate them all\n",
    "#     properties = [('TH.TXT', 'Th'), ('H.TXT', 'H'), ('V.TXT', 'V')]\n",
    "#     if not read_velocities:\n",
    "#         properties = properties[:-1]\n",
    "#     for prop in properties:\n",
    "#         file_path = os.path.join(read_dir, prop[0])\n",
    "#         # Check if the file exists\n",
    "#         if os.path.isfile(file_path):\n",
    "#             prop_df = get_data_from_file(file_path, prop[1])\n",
    "#             full_df = pd.concat([full_df, prop_df], axis=1)\n",
    "#         else:\n",
    "#             print(\n",
    "#                 'Warning, the file {} does not exist in the given path'.format(\n",
    "#                     prop[0]))\n",
    "\n",
    "#     # Convert the num column to integer\n",
    "#     full_df[['n']] = full_df[['n']].astype(np.int64)\n",
    "#     # dropping the first row (the zeros row) as it is not necessary\n",
    "#     full_df.drop(0, inplace=True)\n",
    "#     # Saving the resultant dataframe to disk.\n",
    "#     if save_to_csv:\n",
    "#         full_df.to_csv(os.path.join(read_dir, 'nesr_data2.csv'))\n",
    "#     return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
