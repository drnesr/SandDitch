{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T20:30:56.261886Z",
     "start_time": "2019-07-22T20:30:53.074157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import linecache #as lc\n",
    "import math\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# from decimal import Decimal, ROUND_CEILING\n",
    "import decimal\n",
    "float_formatter = lambda x: \"%.3f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import integrate\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap as LSCm\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "# from matplotlib import rc\n",
    "# rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "# ## for Palatino and other serif fonts use:\n",
    "# #rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "# rc('text', usetex=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for importing and converting HYDRUS output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T20:31:03.643600Z",
     "start_time": "2019-07-22T20:31:03.638603Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_df_from_csv(path, file_name):\n",
    "    _file = os.path.join(path, file_name)\n",
    "    if os.path.isfile(_file):\n",
    "        return pd.read_csv(_file)\n",
    "    else:\n",
    "        print ('Warning, the given path does not contain such given file name, \\\n",
    "        or the path does not exist\\n You provided the file name: {}\\n ... and the \\\n",
    "        path as: {}'.format(file_name, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T20:31:42.524857Z",
     "start_time": "2019-07-22T20:31:42.504868Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_hydrus_data(folder='Current', save_to_csv=True):\n",
    "    '''\n",
    "    A function to read both Theat and H files from HYDRUS outputs, \n",
    "        then to:\n",
    "            1- return one dataframe contains both data in a decent format.\n",
    "            2- save this output to a CSV file (optional, True by default)\n",
    "    Input:\n",
    "        The name of the main folder (leave balank for the current folder)\n",
    "        The option to save_to csv, default =True (Boolean)\n",
    "    '''\n",
    "    # Specify the source folder\n",
    "    if folder=='Current':\n",
    "        read_dir = os.getcwd()\n",
    "    else:\n",
    "        read_dir = folder\n",
    "        \n",
    "    # Finding number of nodes in the file\n",
    "    mesh_file = os.path.join(read_dir, 'MESHTRIA.TXT')\n",
    "    num_cells = np.array(linecache.getline(mesh_file, 6).split(),int)[0]\n",
    "    # Define dataframe titles\n",
    "    titles = ['n', 'x', 'y', 'z'] \n",
    "    # Define a list of coordinates\n",
    "    full_data = [[0,0,0,0]]\n",
    "    # Set a loop to geather all coordinates from MESHTRIA.TXT file\n",
    "    for i in range(8, num_cells + 8):\n",
    "        full_data.append(np.array(linecache.getline(mesh_file, i).split(),float))\n",
    "    # Convert the list to numpy array then to a dataframe\n",
    "    coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)\n",
    "    # Print head and tail of the dataframe to ensure correctness\n",
    "    # pd.concat([coordinates_df.head(),coordinates_df.tail()])\n",
    "    \n",
    "    \n",
    "    # -----------------------------#\n",
    "    # To get data from all files   #\n",
    "    # -----------------------------#\n",
    "    def get_data_from_file(filename='TH.TXT', caption = 'Theta'):\n",
    "        '''\n",
    "        Function to combine all values of a property to a single dataframe \n",
    "        inputs:\n",
    "        filename, the name of the file\n",
    "        caption, the leading caption of the columns (we will add the portion '_T= xxx')\n",
    "        where xxx is the timestep\n",
    "        '''\n",
    "        # compute number of lines for each timestep\n",
    "        num_lines = int(math.ceil(num_cells /10.))\n",
    "        time_steps_remaining = True  # Flag to see if the loop should continue or not.\n",
    "        times_df = pd.DataFrame([])  # Empty dataframe\n",
    "        time_loc_start = 2  # The starting cell of the timestep\n",
    "        while time_steps_remaining:\n",
    "            line_t = linecache.getline(filename, time_loc_start).split()\n",
    "            # Check if it is the start of the timestep, otherwise exit\n",
    "            if line_t[0] == 'Time':\n",
    "                t = int(line_t[2])\n",
    "                # Finding the last line of the timestep\n",
    "                tim_loc_end = num_lines + time_loc_start + 2\n",
    "                # The starting time is always 0 because steps starts in 1 in HYDRUS\n",
    "                time_data = [0]  \n",
    "                # Create the timestep as one long list\n",
    "                for i in range(time_loc_start + 2, tim_loc_end):\n",
    "                    time_data.extend(linecache.getline(filename, i).split())\n",
    "                # Convert the list to DataFrame\n",
    "                dft=pd.DataFrame(np.array(time_data,float),columns=['{}_T={}'.\n",
    "                                                                    format(caption,t)])\n",
    "                if len(times_df) == 0:  # If it is the first timestep\n",
    "                    times_df = dft\n",
    "                else:  # Otherwise (for all other timesteps)\n",
    "                    times_df = pd.concat([times_df, dft], axis=1)\n",
    "                # Change the start to the probable next timestem (if exist)\n",
    "                time_loc_start = tim_loc_end + 1\n",
    "                time_steps_remaining = True if len(linecache.\n",
    "                                                   getline(filename, \n",
    "                                                           time_loc_start)) > 0 else False\n",
    "                # End IF\n",
    "        return times_df\n",
    "    \n",
    "    # Set the basic dataframe to the coordinates dataframe, to append to it.\n",
    "    full_df = coordinates_df\n",
    "    # Looping through the basic output files then to concatenate them all\n",
    "    for prop in [('TH.TXT','Th'), ('H.TXT','H')]:#, ('V.TXT', 'V')]:\n",
    "        file_path = os.path.join(read_dir, prop[0])\n",
    "        # Check if the file exists\n",
    "        if os.path.isfile(file_path):\n",
    "            prop_df = get_data_from_file(file_path, prop[1])\n",
    "            full_df = pd.concat([full_df, prop_df], axis=1)\n",
    "        else: \n",
    "            print ('Warning, the file {} does not exist in the given path'.\n",
    "                   format(prop[0]))\n",
    "\n",
    "    # Convert the num column to integer\n",
    "    full_df[['n']] = full_df[['n']].astype(np.int64)\n",
    "    # dropping the first row (the zeros row) as it is not necessary\n",
    "    full_df.drop(0, inplace=True)\n",
    "    # Saving the resultant dataframe to disk.\n",
    "    if save_to_csv:\n",
    "        full_df.to_csv(os.path.join(read_dir, 'nesr_data2.csv'))        \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_a_level_out(file_path, geom='2D'):\n",
    "    if geom.lower() =='2d':\n",
    "        start = 3\n",
    "    else:\n",
    "        start = 11\n",
    "    filename= os.path.join(file_path, 'A_Level.out')\n",
    "    headers=linecache.getline(filename, start).split()\n",
    "    #boundary conditions\n",
    "    bc1=linecache.getline(filename, start+3).split()\n",
    "    bc2=linecache.getline(filename, start+4).split()\n",
    "    filename= os.path.join(file_path, 'ATMOSPH.IN')\n",
    "    headers += linecache.getline(filename, 7).split()\n",
    "    bc1 += linecache.getline(filename, 8).split()\n",
    "    bc2 += linecache.getline(filename, 9).split()\n",
    "    bcs = np.array([bc1, bc2])\n",
    "    df= pd.DataFrame(data=bcs, columns=headers)\n",
    "    df=df.apply(pd.to_numeric, errors='ignore')\n",
    "    return df\n",
    "    pass\n",
    "# read_a_level_out(source, '3D').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_balance_out(file_path):\n",
    "    filename= os.path.join(file_path, 'Balance.out')\n",
    "    headers=['Time', 'Volume', 'VolumeW', 'InFlow', 'hMean', 'WatBalT', 'WatBalR']\n",
    "    reading = True\n",
    "    start = 5\n",
    "    balance_info={}\n",
    "    while reading:\n",
    "        start +=1\n",
    "        line_feed = linecache.getline(filename, start).split()\n",
    "        feed_len = len(line_feed)\n",
    "        if feed_len < 2: \n",
    "            continue\n",
    "        first_word = line_feed[0].strip()\n",
    "        if first_word == 'Time':\n",
    "            # Initiate record\n",
    "            time = float(line_feed[2])\n",
    "            balance_info[time]={'Volume':None, 'VolumeW':None, \n",
    "                                'InFlow':None, 'hMean':None, \n",
    "                                'WatBalT':None, 'WatBalR':None}\n",
    "        elif first_word in headers:\n",
    "            balance_info[time][first_word]=float(line_feed[2])\n",
    "            \n",
    "#         print(first_word)\n",
    "        if first_word=='Calculation':# or feed_len>115:\n",
    "            simulation_time = line_feed[3]\n",
    "            reading=False\n",
    "    df = pd.DataFrame.from_dict(data=balance_info).T.reset_index()\n",
    "    df.columns.values[0] = 'Time'\n",
    "#     df.rename(columns = {'index':'Time'})\n",
    "    return simulation_time, df#, columns=headers)\n",
    "    pass\n",
    "# results = read_balance_out(source)\n",
    "# print ('Simulation time = {} seconds.'.format(results[0]))\n",
    "# results[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_selector_in(file_path, geom='2D'):\n",
    "    if geom.lower() =='2d':\n",
    "        is2d= True\n",
    "        start = 3\n",
    "    else:\n",
    "        is2d= False\n",
    "        start = 11\n",
    "    filename= os.path.join(file_path, 'SELECTOR.IN')\n",
    "    headers=['L_Unit', 'T_Unit', 'Category']\n",
    "    categ={0:'Horizontal plane XY', \n",
    "           1:'Axisymmetric Vertical Flow', \n",
    "           2:'Vertical Plane XZ',\n",
    "           3:'3D General Domain'}\n",
    "    body =[]\n",
    "    \n",
    "    def proper_type(x):\n",
    "        try:\n",
    "            nf=float(x)\n",
    "            ni = float(int(nf))\n",
    "            # print(nf, ni, abs(nf - ni))\n",
    "            if abs(nf - ni) < 0.0000000000001:\n",
    "                return int(ni)\n",
    "            else:\n",
    "                return nf\n",
    "        except:\n",
    "            return x\n",
    "    \n",
    "    def replace_text(x):\n",
    "        if x in ('t', 'f'):\n",
    "            #return {'t':1, 'f':0}[x]\n",
    "            return ['f', 't'].index(x)\n",
    "        elif x in ('mm', 'cm', 'm'):\n",
    "            return ['mm', 'cm', 'm'].index(x)\n",
    "        elif x in ('sec', 'min', 'hours', 'days', 'years'):\n",
    "            return ['sec', 'min', 'hours', 'days', 'years'].index(x)\n",
    "        elif x in ('s', 'min', 'h', 'd', 'y'):\n",
    "            return ['s', 'min', 'h', 'd', 'y'].index(x)\n",
    "        else:\n",
    "            return x#proper_type(x)\n",
    "    \n",
    "    def get_line(pos):\n",
    "        line_feed=linecache.getline(filename, pos).split()\n",
    "        return list(map(replace_text,line_feed))\n",
    "    \n",
    "    def get_word(pos, loc=0):\n",
    "        word=get_line(pos)\n",
    "        if len(word)<1:\n",
    "            return ''\n",
    "        else:\n",
    "            word = word[loc]\n",
    "        if isinstance(word, str):\n",
    "            return word.strip()\n",
    "        else:\n",
    "            return word\n",
    "    \n",
    "    def get_num(p1, p2):\n",
    "        '''\n",
    "        p1, the line of 2D file\n",
    "        p2, the line of 3D file\n",
    "        '''\n",
    "        return {True: p1, False:p2}[is2d]\n",
    "    \n",
    "    def adjust_body(replaceable):\n",
    "        for _ in range(len(headers)-len(body)):\n",
    "            body.append(replaceable)\n",
    "    \n",
    "\n",
    "    \n",
    "    body.append(get_word(6))\n",
    "    body.append(get_word(7))\n",
    "    body.append({True: int(get_word(10)), False:3}[is2d])\n",
    "    headers += get_line(get_num(11,9))[:4]\n",
    "    body += get_line(get_num(12,10))[:4]\n",
    "\n",
    "    headers += get_line(get_num(13,11))\n",
    "    body += get_line(get_num(14,12))\n",
    "    headers += get_line(get_num(15,13))\n",
    "    body += get_line(get_num(16,14))\n",
    "\n",
    "    headers += get_line(get_num(20,18))\n",
    "    body += get_line(get_num(21,19))\n",
    "    adjust_body(0)\n",
    "    \n",
    "    headers += get_line(get_num(22,20))\n",
    "    body += get_line(get_num(23,21))\n",
    "    \n",
    "    headers += get_line(get_num(24,22))\n",
    "    body += get_line(get_num(25,23)) \n",
    "    \n",
    "    headers += get_line(27)\n",
    "    body += get_line(28)    \n",
    "    headers += get_line(29)\n",
    "    body += get_line(30)\n",
    "    \n",
    "    # Getting data from the DIMENSIO.IN file\n",
    "    filename= os.path.join(file_path, 'DIMENSIO.IN')\n",
    "    headers += get_line(2)\n",
    "    body += get_line(3)\n",
    "    adjust_body(0)\n",
    "    \n",
    "    # Getting data from the Run_Inf.out file\n",
    "    filename= os.path.join(file_path, 'Run_Inf.out')\n",
    "    headers += ['TLevel_i', 'Time_i', 'dt_i', 'Iter_i', 'ItCum_i']\n",
    "    body += get_line(5)\n",
    "    i=6\n",
    "    while get_word(i) != 'end':\n",
    "        i += 1\n",
    "#         print(i, get_word(i), end='||')\n",
    "    headers += ['TLevel_e', 'Time_e', 'dt_e', 'Iter_e', 'ItCum_e']\n",
    "    body += get_line(i-1)\n",
    "    \n",
    "    # Getting data from the Balance.out file\n",
    "    filename= os.path.join(file_path, 'Balance.out')\n",
    "    headers = ['SimulTime_s'] + headers\n",
    "    i=10\n",
    "    while get_word(i) != 'Calculation':\n",
    "        i += 1\n",
    "    body = [get_word(i, loc=3)] + body\n",
    "    \n",
    "    # finalize\n",
    "    body = np.array(body)\n",
    "    headers = np.array(headers)\n",
    "\n",
    "    df=pd.DataFrame(data=body, index=headers).T\n",
    "    df=df.apply(pd.to_numeric, errors='ignore')\n",
    "    return df\n",
    "    pass\n",
    "# res=read_selector_in(source, '2d')\n",
    "# # res.astype(float)\n",
    "# # res.T.astype(float)\n",
    "# # res.astype(float).info()\n",
    "# # res.info()\n",
    "# # print(res.T)\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_line_df(folder_path, simulation_name=\"Nesr simulation\", dims='2d'):\n",
    "    # Get the basic parameters\n",
    "    df_basic = read_selector_in(folder_path, dims)\n",
    "    \n",
    "    # Get the boundary conditions parameters\n",
    "    df_bcs= read_a_level_out(folder_path, dims).T\n",
    "    # converting it to one row\n",
    "    hds0 = ['Time', 'CumQ3', 'hAtm', 'hKode3', 'A-level', 'hCritA', 'rt']\n",
    "    hdsB = ['Time', 'CumQ3', 'hAtm', 'hKode3', 'A-level', 'hCritA', 'Flux_rt']\n",
    "    hds = []\n",
    "    vals = []\n",
    "    for col in df_bcs.columns:\n",
    "        hds += list(map(lambda x: x+'BC{}'.format(col), hdsB))\n",
    "        for idx in hds0:\n",
    "            if idx =='rt':\n",
    "                vals.append(df_bcs.loc[idx, col].iloc[0])\n",
    "            else:\n",
    "                vals.append(df_bcs.loc[idx, col])\n",
    "    df_bcs= pd.DataFrame(data=vals, index=hds).T\n",
    "    \n",
    "    # Get the mass balance parameters\n",
    "    df_bal = read_balance_out(folder_path)[1]\n",
    "    hds0=['InFlow', 'VolumeW', 'WatBalR', 'WatBalT', 'hMean']\n",
    "    hds=[]\n",
    "    vals =[]\n",
    "    for col in hds0:\n",
    "        for idx in df_bal.index:\n",
    "            hds.append(col+str(int(df_bal.loc[idx, 'Time'])))\n",
    "            vals.append(df_bal.loc[idx, col])\n",
    "    df_bal= pd.DataFrame(data=vals, index=hds).T\n",
    "    \n",
    "    # concatenate the 3 dfs\n",
    "    frames = [df_basic, df_bcs, df_bal]\n",
    "\n",
    "    df_result = pd.concat(frames,axis=1)\n",
    "    # df_result.columns\n",
    "    # df_result.rename({'0':\"Custom Name\"}, axis='columns')\n",
    "    df_result = df_result.rename({0:simulation_name}, axis='index')\n",
    "    return df_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "source2 = 'C:/Users/DrNesr/Dropbox/@CurrentWork/@Work/NewHydrus/PYTHONS/sample2d'\n",
    "source3 = 'C:/Users/DrNesr/Dropbox/@CurrentWork/@Work/NewHydrus/PYTHONS/sample3d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimulTime_s</th>\n",
       "      <th>L_Unit</th>\n",
       "      <th>T_Unit</th>\n",
       "      <th>Category</th>\n",
       "      <th>MaxIt</th>\n",
       "      <th>TolTh</th>\n",
       "      <th>TolH</th>\n",
       "      <th>InitH/W</th>\n",
       "      <th>lWat</th>\n",
       "      <th>lChem</th>\n",
       "      <th>...</th>\n",
       "      <th>WatBalT720</th>\n",
       "      <th>WatBalT1440</th>\n",
       "      <th>hMean0</th>\n",
       "      <th>hMean15</th>\n",
       "      <th>hMean60</th>\n",
       "      <th>hMean120</th>\n",
       "      <th>hMean180</th>\n",
       "      <th>hMean360</th>\n",
       "      <th>hMean720</th>\n",
       "      <th>hMean1440</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Nesr simulation</th>\n",
       "      <td>209.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.245</td>\n",
       "      <td>124.33</td>\n",
       "      <td>-10.221</td>\n",
       "      <td>-10.229</td>\n",
       "      <td>-10.262</td>\n",
       "      <td>-10.306</td>\n",
       "      <td>-10.344</td>\n",
       "      <td>-11.299</td>\n",
       "      <td>-13.464</td>\n",
       "      <td>-16.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    SimulTime_s  L_Unit  T_Unit  Category  MaxIt  TolTh  TolH  \\\n",
       "3D Nesr simulation       209.75     1.0     1.0       3.0   10.0  0.001   1.0   \n",
       "\n",
       "                    InitH/W  lWat  lChem    ...      WatBalT720  WatBalT1440  \\\n",
       "3D Nesr simulation      1.0   1.0    0.0    ...          65.245       124.33   \n",
       "\n",
       "                    hMean0  hMean15  hMean60  hMean120  hMean180  hMean360  \\\n",
       "3D Nesr simulation -10.221  -10.229  -10.262   -10.306   -10.344   -11.299   \n",
       "\n",
       "                    hMean720  hMean1440  \n",
       "3D Nesr simulation   -13.464     -16.12  \n",
       "\n",
       "[1 rows x 126 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_one_line_df(source3, simulation_name=\"3D Nesr simulation\", dims='3D').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimulTime_s</th>\n",
       "      <th>L_Unit</th>\n",
       "      <th>T_Unit</th>\n",
       "      <th>Category</th>\n",
       "      <th>MaxIt</th>\n",
       "      <th>TolTh</th>\n",
       "      <th>TolH</th>\n",
       "      <th>InitH/W</th>\n",
       "      <th>lWat</th>\n",
       "      <th>lChem</th>\n",
       "      <th>...</th>\n",
       "      <th>WatBalT720</th>\n",
       "      <th>WatBalT1440</th>\n",
       "      <th>hMean0</th>\n",
       "      <th>hMean15</th>\n",
       "      <th>hMean60</th>\n",
       "      <th>hMean120</th>\n",
       "      <th>hMean180</th>\n",
       "      <th>hMean360</th>\n",
       "      <th>hMean720</th>\n",
       "      <th>hMean1440</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2D Nesr simulation</th>\n",
       "      <td>5.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.2369</td>\n",
       "      <td>-11.118</td>\n",
       "      <td>-10.212</td>\n",
       "      <td>-10.08</td>\n",
       "      <td>-9.6696</td>\n",
       "      <td>-9.0978</td>\n",
       "      <td>-8.5099</td>\n",
       "      <td>-10.481</td>\n",
       "      <td>-13.268</td>\n",
       "      <td>-16.023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    SimulTime_s  L_Unit  T_Unit  Category  MaxIt  TolTh  TolH  \\\n",
       "2D Nesr simulation         5.95     1.0     1.0       2.0   10.0  0.001   1.0   \n",
       "\n",
       "                    InitH/W  lWat  lChem    ...      WatBalT720  WatBalT1440  \\\n",
       "2D Nesr simulation      1.0   1.0    0.0    ...         -7.2369      -11.118   \n",
       "\n",
       "                    hMean0  hMean15  hMean60  hMean120  hMean180  hMean360  \\\n",
       "2D Nesr simulation -10.212   -10.08  -9.6696   -9.0978   -8.5099   -10.481   \n",
       "\n",
       "                    hMean720  hMean1440  \n",
       "2D Nesr simulation   -13.268    -16.023  \n",
       "\n",
       "[1 rows x 126 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_one_line_df(source2, simulation_name=\"2D Nesr simulation\", dims='2D').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "## **Some Auxillary functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to calculate distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance3d(p1, p2=(0, 0, 0)):\n",
    "    ''' \n",
    "    A function to return distance in 3D between two points\n",
    "    If one point is given, the distance to the origin (0, 0, 0) will be returned\n",
    "    The function accept only tuples or lists as inputs\n",
    "    '''\n",
    "    return math.hypot(math.hypot(p2[0] - p1[0], p2[1] - p1[1]), p2[2] - p1[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to get the output grid of the cross section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_grid(source_df_1, axis_of_section='y', grid_value=1., \n",
    "                     default_value=20., output_method='3D', \n",
    "                    is_axisymmetric=False):\n",
    "    ''' \n",
    "    if the output_method is 3D, then it will outputs a list of lists, each sublist\n",
    "    is in the form [x, y, z]\n",
    "    Otherwise, if the output_method ='2D', then the outputs will be in the form\n",
    "    [D1, D2], where D1 and D2 are the other axes than that was specified in the \n",
    "    axis_of_section, i.e. if axis_of_section='y', then D1 and D2 will be x, z.\n",
    "    The default_value is the value that will be appended to all list of list in\n",
    "    the option output_method='3D'\n",
    "    If the axis_of_section='y' and default_value=20., then the outputs will be\n",
    "    [[x1, 20., z1], [x2, 20., z2], ...]\n",
    "    The function returns a tuple of \n",
    "        1- a list of sublists in the form [x, y, z] or [D1, D2] as described\n",
    "            above\n",
    "        2- a list of two linespace arrays of the two coordinates other than that\n",
    "            selected\n",
    "    \n",
    "    '''\n",
    "    if is_axisymmetric:\n",
    "        # if the simulation is Axisymmetric 3D, then take only the \n",
    "        # positive quater to compare with the 2D sections\n",
    "        source_df=source_df_1[(source_df_1.x>=0)&(source_df_1.y>=0)]\n",
    "    else:\n",
    "        source_df=source_df_1\n",
    "        \n",
    "    # find boundaries of x, y, and z (min then max)\n",
    "    src_axis = [axs for axs in ['x', 'y','z'] if axs in source_df.columns]\n",
    "    n_axis = len(src_axis)\n",
    "    inf = source_df.describe()[src_axis].iloc[[3,7]]\n",
    "    inf2 = list(inf.values.T)\n",
    "    mn, mx, iv, lv=[0]*n_axis,[0]*n_axis,[0]*n_axis,[0]*n_axis\n",
    "    grid = grid_value  # cm\n",
    "    for i in range(n_axis):\n",
    "        # minimum and maximum\n",
    "        mn[i], mx[i] = inf2[i]\n",
    "        # number of segments\n",
    "        iv[i] = int(max(abs(mn[i]), abs(mx[i])) // grid) + 1\n",
    "        # grid of coordinates\n",
    "        lv[i] = np.linspace(mn[i],mx[i],iv[i])\n",
    "        pass\n",
    "\n",
    "\n",
    "     # Now specify the used axes perpendicular to the section\n",
    "     # I want to define the variable outside the if condition\n",
    "    used_axes = (0, 2) # if the default axis, y, is used\n",
    "    if axis_of_section.lower() == 'x':\n",
    "        used_axes = (1, 2)\n",
    "    elif axis_of_section.lower() == 'z':\n",
    "        used_axes = (0, 1)\n",
    "    else:\n",
    "        pass  # it is 'y'\n",
    "    cros_section_grid = []\n",
    "#     print(output_method)\n",
    "    if output_method !='3D': # =='2D' for example\n",
    "        used_axes = (0, 1)\n",
    "        for outer in lv[used_axes[0]]:\n",
    "            for inner in lv[used_axes[1]]:\n",
    "                cros_section_grid.append((outer, inner))\n",
    "                pass\n",
    "            pass\n",
    "    else:  # output_method =='3D'\n",
    "        for outer in lv[used_axes[0]]:\n",
    "            for inner in lv[used_axes[1]]:\n",
    "                if axis_of_section.lower() == 'x':\n",
    "                    x, y, z = default_value, outer, inner\n",
    "                elif axis_of_section.lower() == 'z':\n",
    "                    x, y, z = outer, inner, default_value\n",
    "                else:  # the default axis_of_section='y'\n",
    "                    x, y, z = outer, default_value, inner\n",
    "                cros_section_grid.append((x, y, z))\n",
    "                pass\n",
    "            pass\n",
    "#     return mn, mx, iv, list(lv[0])\n",
    "    return cros_section_grid, (lv[used_axes[0]], lv[used_axes[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to get a sliced dataframe for the desired variable at specific axis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_dataframes(source_df, axis_of_section='y', cross_at=20., \n",
    "                           tolerance=15., output='before & after'):\n",
    "    '''\n",
    "    reads a dataframe, and slices it on x, y, or z axis at a specic location \n",
    "    then returns one or two dataframes contain all the points within a specific \n",
    "    tolerance around the cross section.\n",
    "    Inputs:\n",
    "        1- the main dataframe\n",
    "        2- the axis of section to slice at (default is y-axis) {'x', 'y', 'z'}\n",
    "        3- the value at which the cross section occur (default = 20. cm) {float}\n",
    "        4- the tolerance of the setion (how long the slice will take after and \n",
    "            before the cross section)(default = 15. cm) {float}\n",
    "        5- how to output (what will return?)\n",
    "            {a- 'before & after', returns two dataframes, one to the left \n",
    "                and other to the right of it (default)\n",
    "             b- 'all', one dataframe contains the two dataframes merged}\n",
    "        \n",
    "    '''\n",
    "    # let us try to get points around the section Y=20\n",
    "    # it is a section at XZ direction, so we have all values of X and Z\n",
    "    # but only values of Y=20 plus or minus a tolerance (say 10 cm)\n",
    "    if axis_of_section.lower() =='x':\n",
    "        sec_at = source_df.x # the axis of the section\n",
    "    elif axis_of_section.lower() =='y':\n",
    "        sec_at = source_df.y # the axis of the section\n",
    "    else:  # axis_of_section ='z'\n",
    "        sec_at = source_df.z # the axis of the section\n",
    "        pass\n",
    "    \n",
    "    sec_val = cross_at # the value at which the section occur\n",
    "    sec_tol = tolerance # the tolerance of the section\n",
    "    # Find minimum value of the section axis\n",
    "    sec_min = sec_val - sec_tol\n",
    "    sec_max = sec_val + sec_tol\n",
    "    # (to overcome the negative values problem)\n",
    "    sec_min, sec_max = min(sec_min, sec_max), max(sec_min, sec_max)  \n",
    "    # theta[(theta.y>=10) & (theta.y<=30)].shape\n",
    "    if output == 'before & after':\n",
    "        # Then we find two dataFrames, one after the point, and one before it\n",
    "        df_after = source_df[(sec_at>=sec_val) & (sec_at<=sec_max)]  #.shape\n",
    "        df_before = source_df[(sec_at>=sec_min) & (sec_at<=sec_val)]  #.shape\n",
    "    #     return df_before.shape, df_after.shape\n",
    "        return df_before, df_after\n",
    "    else: # outputs one dataframe\n",
    "        df_full = source_df[(sec_at>=sec_min) & (sec_at<=sec_max)]  #.shape\n",
    "        return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_values(data_frame, variable=0, time_step = 180, grid = 0.5, \n",
    "                    crosses = 35., tol = 10., section ='x', \n",
    "                    testing=False, is2d=False, is_axisymmetric=False):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Find the variable mask\n",
    "    v_mask = {0:'Th', 1:'H'}[variable] # , 2:'V'\n",
    "    if testing: print(v_mask)\n",
    "        \n",
    "    # first get the dataframe of the neighbors of the required cross-section\n",
    "    # (source_df, axis_of_section='y', cross_at=20., tolerance=15., \n",
    "    #   output='before & after')\n",
    "#     print('is2d from get_grid_values: ', is2d)\n",
    "    if is2d:\n",
    "        src = data_frame\n",
    "        scr_cols=[axs for axs in ['x', 'y','z'] if axs in data_frame.columns]     \n",
    "        points = np.array(src[scr_cols])\n",
    "    else:\n",
    "        src= get_section_dataframes(data_frame, axis_of_section=section, \n",
    "                                    cross_at=crosses, tolerance=tol, output='full')\n",
    "        points = np.array(src[['x', 'y','z']])\n",
    "    z_values = np.array(src[['{}_T={}'.format(v_mask, time_step)]])\n",
    "    if testing: print ('src shape:{}, points shape:{}, z_values shape::'.\n",
    "                       format (src.shape, points.shape, z_values.shape))\n",
    "    if testing: print(src[['{}_T={}'.format(v_mask, time_step)]].head())\n",
    "    # get the grid info\n",
    "    # (source_df, axis_of_section='y', grid_value=1., default_value=20., output_method='3D')\n",
    "    if is2d:\n",
    "        cs = get_section_grid(data_frame, \n",
    "                              axis_of_section='y', grid_value=grid, \n",
    "                              default_value=0., output_method='2D')\n",
    "    else:\n",
    "        cs = get_section_grid(data_frame, axis_of_section=section, \n",
    "                              grid_value=grid, default_value=crosses, \n",
    "                              output_method='3D', \n",
    "                              is_axisymmetric=is_axisymmetric)\n",
    "    \n",
    "    requests = np.array(cs[0])\n",
    "    # x_vals, z_vals are the two used axes, regardless they are XY, XZ, or YZ\n",
    "    x_vals, z_vals = cs[1][0], cs[1][1]\n",
    "    if testing: print ('requests shape:{}, x_vals shape:{}, z_vals shape:{}'.\n",
    "                       format (requests.shape, x_vals.shape, z_vals.shape))\n",
    "    \n",
    "    X, Z = np.meshgrid(x_vals, z_vals)\n",
    "#     M = griddata(points, z_values, requests).reshape((X.shape[1], X.shape[0])).T\n",
    "    if testing: print ('points shape:{}, z_values shape:{}, requests shape:{}'.\n",
    "                       format (points.shape, z_values.shape, requests.shape))\n",
    "\n",
    "    M = griddata(points, z_values, requests).reshape((X.shape[1], X.shape[0])).T\n",
    "\n",
    "    return X, Z, M, x_vals, z_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_timesteps(data_frame):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    cols = list(data_frame.head())\n",
    "    mems = list(filter(lambda x: x.find('_T')>0, cols))\n",
    "    return sorted(list(set(map(lambda x: int(float(x.split('=')[1])),mems))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_dimensions(data_frame):\n",
    "    xyz = {}\n",
    "    for dim in ['x', 'y', 'z']:\n",
    "        if dim in data_frame.columns:\n",
    "            _t = data_frame[dim]\n",
    "            _t = _t.min(), _t.max() \n",
    "            xyz[dim]=_t\n",
    "    #     mems = list(filter(lambda x: x.find('h_T')>0, cols))\n",
    "    return xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd(number, significant_digits=8):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    return round(number*10**significant_digits)/10.**significant_digits\n",
    "\n",
    "def round_to_significance(number, significance, direction='up'):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    if direction == 'up':\n",
    "        num = math.ceil(number/significance) * significance\n",
    "    else: \n",
    "        num = math.floor(number/significance) * significance\n",
    "    return rnd (num, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_series(series, odd_envelop=51, plynomial_degree=3):\n",
    "    '''\n",
    "    A simple function to use savgol_filter to smooth any array-like series\n",
    "    the odd_envelop must be odd number, if an even is giver, it will be \n",
    "    increased by 1, plynomial_degree must be >=2, other wize it will be \n",
    "    set to 3.\n",
    "    one must to add the statement from scipy.signal import savgol_filter \n",
    "    at the begining of the code.\n",
    "    '''\n",
    "    # correcting the inputs\n",
    "    if odd_envelop % 2 !=1:\n",
    "        odd_envelop +=1\n",
    "    if odd_envelop <3:\n",
    "        odd_envelop = 3\n",
    "    if plynomial_degree<2:\n",
    "        plynomial_degree =3\n",
    "    odd_envelop = int(odd_envelop)\n",
    "    plynomial_degree =int(plynomial_degree)\n",
    "    \n",
    "#     if isinstance(series, pd.Series):\n",
    "#     if isinstance(series, np.ndarray):\n",
    "    if not isinstance(series, pd.Series):\n",
    "        sss= savgol_filter(series, odd_envelop, plynomial_degree)\n",
    "        return pd.Series(sss)\n",
    "    else:\n",
    "        return pd.Series(savgol_filter(series, odd_envelop, plynomial_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legend_range(mn, mx):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    rg = mx - mn\n",
    "    vnn = '{:.2E}'.format(rg)\n",
    "    ew=vnn.split('E')\n",
    "    ws = float(ew[0]), float(ew[1])\n",
    "    wq = int(float(ew[0])), 10**int(float(ew[1]))/10.\n",
    "    step = wq[0]*wq[1]\n",
    "    rn = round_to_significance(mn, step, direction='up')\n",
    "    rx = round_to_significance(mx, step, direction='dn')\n",
    "#     return vnn, ew, ws, wq, rr, rnd(rr)\n",
    "    # return vnn, ws, wq, step, (mn,rn), (mx, rx), np.arange(rn+step, \n",
    "    # rx+step, step)\n",
    "    return np.arange(rn+step, rx+step, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contour(X, Z, M, levels=None, \n",
    "                 plot_title=\"ElNesr cross sectional contour map\",\n",
    "                x_step=10., z_step=25., mirror_x=False, mirror_z=False,\n",
    "                return_figure_object=False):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "#     print('mir_X draw_contour: ', mirror_x)\n",
    "    fig = plt.figure(num=None, figsize=(18, 7), dpi=80, facecolor='w', edgecolor='k');\n",
    "    origin = 'lower'\n",
    "    \n",
    "    if levels is None:\n",
    "#         print(M.min(), M.max())\n",
    "        try:\n",
    "#             levels = get_legend_range(M.min(), M.max())#np.arange(0.15, 0.42, 0.03)\n",
    "            levels = get_legend_range(np.nanmin(M),np.nanmax(M))#np.arange(0.15, 0.42, 0.03)\n",
    "        except:\n",
    "            levels = get_legend_range(-.15, 0.15)\n",
    "        \n",
    "#     CS_lines = plt.contour (X, Z, M, levels, cmap=plt.cm.Accent_r, \n",
    "#                             linewidths=(2,), origin=origin, extend='both')\n",
    "    CS_lines = plt.contour (X, Z, M, levels, cmap=plt.cm.Accent_r, \n",
    "                            linewidths=(0.25,), origin=origin, extend='both')\n",
    "    \n",
    "    CS_fill  = plt.contourf(X, Z, M, levels, cmap=plt.cm.YlGn, \n",
    "                            origin=origin, extend='both')\n",
    "    \n",
    "    CS_fill.cmap.set_under('oldlace')\n",
    "    CS_fill.cmap.set_over('darkslategrey')\n",
    "    plt.title(plot_title)\n",
    "    plt.ylabel(\"Depth (cm)\")\n",
    "    cols = plt.cm.Accent_r(CS_lines.norm(CS_lines.levels))\n",
    "    plt.clabel(CS_lines, linewidths=4, fmt='%2.2f', fontsize='x-large', \n",
    "               colors=cols, inline=True, inline_spacing=10)\n",
    "    plt.colorbar(CS_fill)\n",
    "#     print(Z.min(), Z.max(), X.min(), X.max())\n",
    "#     print(plt.xlim)\n",
    "\n",
    "    def adjust_max_and_min(_min, _max, _step):\n",
    "        nn, xx, ss = _min, _max, _step\n",
    "        if xx <= 0.:\n",
    "            nn, xx = xx, nn\n",
    "            if ss>0:\n",
    "                ss = -ss\n",
    "        return nn,xx, ss\n",
    "        \n",
    "    def adjust_axis_labels(_min, _max, _step):\n",
    "        nn, xx, ss = adjust_max_and_min(_min, _max, _step)\n",
    "\n",
    "        x_list = np.arange(nn,xx, ss)\n",
    "        if abs(x_list[-1]-xx)>3: # The last number is far enough from \n",
    "                                 # the maximum element\n",
    "            x_list = np.hstack([x_list, xx])\n",
    "        else:  # The last number is too close to the maximum element\n",
    "            x_list = np.hstack([x_list[:-1], xx])\n",
    "        return x_list\n",
    "\n",
    "    def adjust_mirrored_labels(_min, _max, _step):\n",
    "#         print(_min, _max, _step)\n",
    "        nn, xx, ss = adjust_max_and_min(_min, _max, _step)\n",
    "#         print(nn, xx, ss)\n",
    "        x_mid=(xx-nn)/2.\n",
    "#         print(x_mid)\n",
    "        \n",
    "        if x_mid < 0:\n",
    "            right_list = adjust_axis_labels(min(x_mid, xx), max(x_mid, xx), ss)\n",
    "#             print('Right list',right_list)\n",
    "            left_list = right_list - x_mid\n",
    "#             print('left List',left_list)\n",
    "            right_list = x_mid - right_list \n",
    "#             print('Right list2',right_list)\n",
    "            \n",
    "            left_list.sort()\n",
    "#             print('left List2', left_list)\n",
    "\n",
    "            label_list = np.hstack([left_list[:-1], right_list])\n",
    "#             print('Label list',label_list)\n",
    "            \n",
    "            real_list =x_mid-label_list \n",
    "#             print('Real list',real_list)\n",
    "            label_list=label_list[::-1]\n",
    "#             print('Label list3',label_list)\n",
    "            return real_list, label_list\n",
    "        elif x_mid > 0:\n",
    "            right_list = adjust_axis_labels(x_mid, xx, ss)\n",
    "#             print('Right list',right_list)\n",
    "            left_list = 2 * x_mid - right_list\n",
    "#             print(left_list)\n",
    "            left_list.sort()\n",
    "#             print(left_list)\n",
    "            real_list = np.hstack([left_list[:-1], right_list])\n",
    "#             print(real_list)\n",
    "            label_list =real_list - x_mid\n",
    "#             print(label_list)\n",
    "            label_list =tuple(['{:3.1f}'.format(x) for x in label_list])\n",
    "#             print(label_list)\n",
    "            return real_list, label_list\n",
    "        else:\n",
    "            real_list, label_list = None, None\n",
    "            return real_list, label_list\n",
    "            \n",
    "        \n",
    "        \n",
    "#     print('mir_X draw_contour2: ', mirror_x, 'x_step: ', x_step)\n",
    "    if mirror_x:\n",
    "        if x_step is not None:\n",
    "            ticks, labels = adjust_mirrored_labels(X.min(),X.max(), x_step)\n",
    "#             print(ticks, labels)\n",
    "            plt.xticks(ticks, labels)\n",
    "    else: # No Mirroring\n",
    "        if x_step is not None:\n",
    "            plt.xticks(adjust_axis_labels(X.min(),X.max(), x_step))\n",
    "\n",
    "    if mirror_z:\n",
    "        if z_step is not None:\n",
    "            ticks, labels = adjust_mirrored_labels(Z.min(),Z.max(), z_step)\n",
    "            plt.yticks(ticks, labels)\n",
    "    else: # No Mirroring\n",
    "        if z_step is not None:\n",
    "            plt.yticks(adjust_axis_labels(Z.min(),Z.max(), z_step))\n",
    "#     ax=plt.axes()\n",
    "    ax = plt.gca()\n",
    "    ax.grid(True, zorder=0)\n",
    "#     plt.axes().xaxis.grid(True, zorder=0)\n",
    "#     plt.axes().yaxis.grid(True, zorder=0)\n",
    "    # plt.colorbar(CS_lines)\n",
    "    if return_figure_object:\n",
    "        return fig\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_full_contour(data_frame,variable=0, time_step=180, grid= 0.5, \n",
    "                      crosses=35., tol=10., section= 'x', levels=None,\n",
    "                      plot_title=\"ElNesr cross sectional contour map\",\n",
    "                      return_arrays=True, x_step=None, z_step=None, \n",
    "                      mirror_x=False, mirror_z=False, is2d=False, \n",
    "                      output_the_contour=True, is_axisymmetric=False,\n",
    "                      return_figure_object=False):\n",
    "    \n",
    "    '''\n",
    "    Either (1) set the return_arrays to True and use on right \n",
    "                hand side of equal sign, \n",
    "    OR     (2) set the return_arrays to False and use the function as is.\n",
    "    Examples:\n",
    "    (1)\n",
    "       arrays = draw_full_contour(data_frame,variable, time_step, grid, \n",
    "                                   crosses, tol, section)\n",
    "       It will draws the chart AND sets arrays=X, Z, M, levels\n",
    "    (2)\n",
    "       draw_full_contour(data_frame,variable, time_step, grid, crosses, \n",
    "                           tol, section, return_arrays=False)    \n",
    "    '''\n",
    "#     print('is2d=', is2d)\n",
    "    X, Z, M, x_vals, z_vals = get_grid_values(data_frame, variable, \n",
    "                                              time_step, grid, crosses, \n",
    "                                              tol, section, is2d=is2d,\n",
    "                                             is_axisymmetric=is_axisymmetric)\n",
    "    # print(x_vals.shape, z_vals.shape, X.shape, Z.shape, M.shape)\n",
    "    if levels is None:\n",
    "        levels = get_legend_range(np.nanmin(M),np.nanmax(M))#np.arange(0.15, 0.42, 0.03)\n",
    "\n",
    "    mn, mx = np.nanmin(M),np.nanmax(M)\n",
    "    # print (mx,mn, mx-mn)\n",
    "    if mx - mn < 0.000000001:\n",
    "        print('For the requested contour map of {}'.format(plot_title), end='. ')\n",
    "        print (\"The map has one value only ({}), no contour map will be drawn.\".\n",
    "               format(mn))\n",
    "        can_draw_figure=False\n",
    "    else:\n",
    "        can_draw_figure=True\n",
    "    \n",
    "    if not output_the_contour and not return_figure_object:\n",
    "        fig = None\n",
    "    else:\n",
    "        if can_draw_figure:\n",
    "            fig = draw_contour(X, Z, M, levels, plot_title, x_step, z_step, \n",
    "                             mirror_x, mirror_z, return_figure_object);\n",
    "        else:\n",
    "            fig = None\n",
    "        \n",
    "#     exit()\n",
    "    if return_arrays:\n",
    "        if output_the_contour:\n",
    "            if return_figure_object:\n",
    "                return X, Z, M, levels, fig\n",
    "            else: # return_figure_object=False\n",
    "                display(fig)\n",
    "                return X, Z, M, levels\n",
    "        else:  #output_the_contour=False\n",
    "            if return_figure_object:\n",
    "                return X, Z, M, levels, fig\n",
    "            else: # return_figure_object=False\n",
    "                return X, Z, M, levels\n",
    "    else:  #return_arrays=False\n",
    "        if output_the_contour:\n",
    "            if return_figure_object:\n",
    "                return fig\n",
    "            else: # return_figure_object=False\n",
    "                display(fig)\n",
    "        else:  #output_the_contour=False\n",
    "            if return_figure_object:\n",
    "                return fig\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_crossed_at_list(cs_list):\n",
    "        ''' read the reduce_auto_list above'''\n",
    "        a1, an = cs_list[0], cs_list[-1]\n",
    "        if len(cs_list) %2 ==1: # Odd list\n",
    "            cs2= cs_list[1:-1][1::2]\n",
    "            return np.hstack([a1, cs2, an])\n",
    "        else: # even list\n",
    "            cs2= cs_list[1:-1]\n",
    "            zl = zip (cs2[::2], cs2[1::2])\n",
    "            return np.hstack([a1, list(map(np.mean, list(zl))), an])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cross_sections(input_array, xs_array, zs_array, direction='z', \n",
    "                        crossed_at_list=None, number_of_sections=10,\n",
    "                       measured_value='Th', reduce_auto_list=False):\n",
    "    '''\n",
    "    inputs:\n",
    "        input_array, xs_array, zs_array are two_dim_array is a 2D array, \n",
    "        may be numpy array or a list of lists\n",
    "        xs_array, zs_array might be 1D arrays\n",
    "        direction:  if = 'z' the curves represent cross sections at z e.g -30, -15\n",
    "                    if = 'x' the curves represent cross sections at x e.g. 45, 60\n",
    "                    if = 'y' the curves represent cross sections at y e.g. 45, 60\n",
    "        crossed_at_list if None, then it requires number_of_sections that \n",
    "                                        will be calculated\n",
    "        measured_value='Th' if the curves represent moisture content (default), or \n",
    "                       'H' if the curves represent suction pressure \n",
    "        reduce_auto_list: if the crossed_at_list is not provided(None), \n",
    "                        then if this is True, \n",
    "                   it will take every other line in the generated list. \n",
    "                   For example:\n",
    "                   if the generated list is [0, 10, 20, 30 ,40, 50, 60] \n",
    "                   it will display only \n",
    "                   [0, *, 20, * ,40, *, 60] only. \n",
    "                   while if the provided list is even [0,,,,70]\n",
    "                   it will display [0, 15, 35, 55, 70]. the default is False\n",
    "    '''\n",
    "#     colors=[(1, 0, 0), (0, 1, 0), (0, 0, 1)] # R -> G -> B\n",
    "#     colors=['indigo', 'darkviolet', 'darkblue', 'blue', 'darkmagenta', 'darkcyan', \n",
    "#             'darkgreen', 'darkolivegreen', 'olive', 'darkgoldenrod', 'firebrick', \n",
    "#                 'red' ] # R -> G -> B\n",
    "#     colors=['darkviolet', 'darkblue', 'blue', 'magenta', 'darkcyan', 'darkgreen', \n",
    "#             'green', 'y', 'darkorange', 'firebrick', 'red']    \n",
    "    colors=['darkviolet', 'y','blue', 'gold','darkgreen','darkcyan', 'yellow','red']\n",
    "#     random.shuffle(colors)\n",
    "#     print (colors)\n",
    "    cmap_name = 'Nesr_cmap'\n",
    "    n_bin=len(colors)*2\n",
    "    cm = LSCm.from_list(cmap_name, colors, N=n_bin)\n",
    "    col_map = ['Paired', 'nipy_spectral', 'brg', 'prism', 'tab10', \n",
    "               'tab20', 'tab20b'][0]\n",
    "    col_map = cm\n",
    "    def reduce_crossed_at_list(cs_list):\n",
    "            ''' read the reduce_auto_list above'''\n",
    "            a1, an = cs_list[0], cs_list[-1]\n",
    "            if len(cs_list) %2 ==1: # Odd list\n",
    "                cs2= cs_list[1:-1][1::2]\n",
    "                return np.hstack([a1, cs2, an])\n",
    "            else: # even list\n",
    "                cs2= cs_list[1:-1]\n",
    "                zl = zip (cs2[::2], cs2[1::2])\n",
    "                return np.hstack([a1, list(map(np.mean, list(zl))), an])            \n",
    "                \n",
    "    \n",
    "    def draw_cs_x(depth_df, cs_range, axis_label, title_part):\n",
    "#         plt.rc('text', usetex=True)\n",
    "#         plt.rc('font', family='serif')\n",
    "        \n",
    "#         cs_range = np.arange(-50, 0, 5)\n",
    "        depth_cs_df=[]\n",
    "        for sec in cs_range:\n",
    "            current_series= depth_df.loc[sec]\n",
    "            name = '@{:04.1f} cm'.format(current_series.name)\n",
    "            idx =  current_series.index\n",
    "            smoothed = smooth_series(current_series)\n",
    "            smoothed.index = idx\n",
    "            smoothed.name = name\n",
    "            depth_cs_df.append(smoothed)\n",
    "\n",
    "        depth_cs_df= pd.concat(depth_cs_df,axis=1)\n",
    "        depth_cs_df.head(10)\n",
    "        xs =depth_df.columns\n",
    "        ax = depth_cs_df.plot(figsize=(9,6), grid=True, colormap=col_map, \n",
    "                              xlim=(xs.min(), xs.max()) )\n",
    "        ax.set_ylabel(axis_label, fontsize=12)\n",
    "        ax.set_xlabel(r'Horizontal distance in {} direction $(cm)$'.\n",
    "                      format(direction), fontsize=12)\n",
    "        _ti='The change in {} accross the horizontal distance, at different depths'\n",
    "        ax.set_title(_ti.format(title_part),\n",
    "                     fontsize=16, y=1.08)\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def draw_cs_z(x_df, cs_range, axis_label, title_part):\n",
    "        x_cs_df=[]\n",
    "        for sec in cs_range:\n",
    "            ts=x_df.loc[:,sec].reset_index()\n",
    "            ts.rename(columns={ts.columns[0]: \"@{:04.1f} cm\".\n",
    "                               format(ts.columns[1]), \n",
    "                               ts.columns[1]: 'Value'}, inplace=True)\n",
    "            sss=ts['Value'].apply(lambda x: int(x*1000)/1000)\n",
    "            ts['Value']= smooth_series(sss)\n",
    "            ts.set_index('Value', inplace=True)\n",
    "            x_cs_df.append(ts)\n",
    "        x_cs_df= pd.concat(x_cs_df,axis=0)#, keys='df{}'.format(cs_range))\n",
    "        # ms =depth_df.values\n",
    "        zs =depth_df.index\n",
    "        ax = x_cs_df.plot(figsize=(6,8), grid=True, colormap=col_map,\n",
    "                          ylim=(zs.min(), zs.max())) #, xlim=(ms.min(), ms.max()) )\n",
    "        ax.set_xlabel(axis_label, fontsize=12)\n",
    "        _ti='The change in {} accross depth, at different horizontal distances'\n",
    "        ax.set_ylabel(r'Depth under soil $(cm)$',fontsize=12)\n",
    "        ax.set_title(_ti.format(title_part),\n",
    "                     fontsize=16, y=1.08)\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10),\n",
    "                  fancybox=True, shadow=True, ncol=5)\n",
    "        pass    \n",
    "    \n",
    "    \n",
    "    # Correct inputs to be numpy arrays\n",
    "    inputs = [input_array, xs_array, zs_array]\n",
    "    for i, lst in enumerate(inputs):\n",
    "        if isinstance(lst, list):\n",
    "            inputs[i] = np.ndarray(lst)\n",
    "    input_array, xs_array, zs_array = inputs \n",
    "    \n",
    "    # Check if the xs and zs are passed as 2Dim or 1Dim.\n",
    "    # If passed as 2D, we take the axis that is corresponding to each.\n",
    "    if xs_array.ndim == 2:\n",
    "        _x = xs_array[0,:]\n",
    "    if zs_array.ndim == 2:\n",
    "        _z = zs_array[:,0]\n",
    "\n",
    "    depth_df = pd.DataFrame(input_array, index=_z, columns=_x, dtype=float)\n",
    "    \n",
    "    #Create the crossing list if none provided\n",
    "    if crossed_at_list is None:\n",
    "        if direction == 'x' or direction == 'y':\n",
    "            zx, zn = _z.max(), _z.min()\n",
    "        elif direction == 'z':\n",
    "            zx, zn = _x.max(), _x.min()\n",
    "        step = (zx - zn)/number_of_sections\n",
    "        cs_range = np.arange(zn, zx, step)\n",
    "        if reduce_auto_list:\n",
    "            cs_range = reduce_crossed_at_list(cs_range)\n",
    "    \n",
    "    # set the axis labels\n",
    "    if measured_value == 'Th':\n",
    "        axis_label = r'Moisture content $(cm^{3}/cm^{3})$'\n",
    "        title_part = 'moisture content'\n",
    "    elif measured_value == 'H':\n",
    "        axis_label = r'Pressure head $(cm)$'\n",
    "        title_part = 'pressure head'\n",
    "    else:\n",
    "        axis_label = 'Undefined measure'\n",
    "        title_part = 'undefined measure'\n",
    "        \n",
    "    \n",
    "    function = {'x': draw_cs_x, 'y': draw_cs_x, 'z': draw_cs_z}\n",
    "    function[direction](depth_df, cs_range, axis_label, title_part)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_volume(sX, sZ, sM, method='Simp', get_average=False, \n",
    "                     separate_negatives=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if separate_negatives:\n",
    "        # in this case, the sM will be divided into two arrays, \n",
    "#         one with positives, and one for negatives\n",
    "        positives_array = np.where(sM>0,sM,0)\n",
    "        positives_results = integrate_volume(sX, sZ, positives_array, \n",
    "                                             method=method, \n",
    "                                             get_average=get_average, \n",
    "                                             separate_negatives=False)\n",
    "        negatives_array = np.where(sM<=0,sM,0)\n",
    "        negatives_results = integrate_volume(sX, sZ, negatives_array, \n",
    "                                             method=method, \n",
    "                                             get_average=get_average, \n",
    "                                             separate_negatives=False)\n",
    "        if get_average:\n",
    "            total_results = (positives_results[0]+negatives_results[0], \n",
    "                            positives_results[1]+negatives_results[1], \n",
    "                            positives_results[2])\n",
    "        else:\n",
    "             total_results = positives_results+negatives_results\n",
    "        return positives_results, negatives_results, total_results\n",
    "    \n",
    "    requested_method = method.lower()[:4]\n",
    "    if requested_method == 'simp':\n",
    "        vol = integrate.simps(integrate.simps(sM, sX, axis=1),sZ)\n",
    "    elif requested_method == 'trap':\n",
    "        vol = np.trapz(np.trapz(sM, sX, axis=1),sZ)\n",
    "    else: # requested_method == 'mean':\n",
    "        vol = 0.5 * (integrate.simps(integrate.simps(sM, sX, axis=1),sZ) \n",
    "                     + np.trapz(np.trapz(sM, sX, axis=1),sZ))\n",
    "    if get_average:\n",
    "        Lx, Lz = (sX.max()-sX.min()), (sZ.max()-sZ.min())\n",
    "        area= Lx*Lz\n",
    "        return vol, vol/area, area\n",
    "    else:\n",
    "        return vol\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_difference(arr1, arr2, scale_from=0, custom_levels=None,\n",
    "                    x_step=10., z_step=25., mirror_x=False, mirror_z=False, \n",
    "                    calculate_volume=False, calculate_average=False, \n",
    "                    no_contours=False, separate_negatives=False,\n",
    "                    calculate_volume_percent=False,\n",
    "                    return_calculations=True, return_figure_object=False):\n",
    "    \"\"\"\n",
    "    A function that calculates the difference between two arrays. \n",
    "    Main inputs:\n",
    "    arr1, arr2: the two arrays that will calculate the difference from each other,\n",
    "                    Each array shoud be a tuple of (X, Z, M, levels),  \n",
    "                    all should be nupy arrays of the same size,\n",
    "                    the difference will be calculated (arr1-arr2)\n",
    "    scale_from: The levels of the contour will be taken from arr1, unless \n",
    "                    this argument is adjusted to be = 2, \n",
    "                    then we will take x, y, levels from arr2\n",
    "                    Default=0\n",
    "    custom_levels: Only if the scale_from=0, the contour levels will be read from\n",
    "                    what is provided by custom_levels, they should be a tuple \n",
    "                    in the format (min, max, step)\n",
    "                    Default=None\n",
    "    x_step: The step of the scale in the horizontal (x) direction, Default=10.\n",
    "    z_step: The step of the scale in the vertical (z) direction, Default=25.\n",
    "    mirror_x: If true, the x values will be shown as 0 in the middle, \n",
    "                    positive values to its right, and negative values to its left\n",
    "                    Default=False\n",
    "    mirror_z: If true, the z values will be shown as 0 in the middle, \n",
    "                    positive values upward, and negative values downward\n",
    "                    Default=False\n",
    "    calculate_volume: if True, the function will calculate the full volume \n",
    "                    of the difference\n",
    "                    Default= False\n",
    "    calculate_average: if True, the function will calculate the average \n",
    "                    moisture/head of the difference\n",
    "                    Default= False\n",
    "    no_contours: if True, the function will not return any drawing, it will \n",
    "                    just return volumemand average moisture if they are selected. \n",
    "                    Default=False\n",
    "    separate_negatives: If True, the calculated volumes and heights will \n",
    "                    be performed for positives and negatives individually, \n",
    "                    then will be added together.\n",
    "                    \n",
    "    It has 2 main outputs:\n",
    "    1- Draws a contour map of the difference if no_contours=False, or not set \n",
    "        (the default =False)\n",
    "    2- Outputs the volume stuff: (IF the calculate_volume_percent=False)\n",
    "        a- If calculate_average=True, and separate_negatives=False,\n",
    "                it will output a tuple of:(volume, average, section area)\n",
    "        b- If calculate_average=False, and separate_negatives=False, \n",
    "                it will return the volume only (float)\n",
    "        c- If calculate_average=True, and separate_negatives=True, \n",
    "                it will return a tuple of 3 tuples, each one contains:\n",
    "                a tuple of  (volume, average, section area). \n",
    "                The 3 tuples are for \n",
    "                (positives, negatives, and totals) {respectively}\n",
    "        d- If calculate_average=False, and separate_negatives=True, \n",
    "                it will return a tuple of 3 tuples, each one contains:\n",
    "                a tuple of  (volume). The 3 tuples are for \n",
    "                (positives, negatives, and totals) {respectively}\n",
    "    *- IF the calculate_volume_percent=True:\n",
    "            The function will return the same outputs from 2 plus\n",
    "            number of members will be added to the difference tuple:\n",
    "            a- a tuple of (vol_diff/vol_base, avg_diff/avg_base)\n",
    "            b- a tuple of (vol_diff/vol_base)\n",
    "            c- a tuple of tuples ((p), (n), (t)), where each of p, n, t  is\n",
    "                  of the form(vol_diff/vol_base, avg_diff/avg_base) for \n",
    "                  positives, negatives, and totals respectively.\n",
    "            d- a tuple of (p, n, t), where each of p, n, t  is\n",
    "                  of the form(vol_diff/vol_base) for \n",
    "                  positives, negatives, and totals respectively.\n",
    "                \n",
    "    If both calculate_volume=False, and no_contours=False, \n",
    "    it will return None with a warning\n",
    "    \"\"\"\n",
    "    # To draw diffecence between two contour maps\n",
    "    if scale_from ==2:\n",
    "        _x, _z, _m , _levels= arr2\n",
    "        difference_matrix = arr2[2]-arr1[2]\n",
    "    else:\n",
    "        _x, _z, _m , _levels= arr1\n",
    "        difference_matrix = arr1[2]-arr2[2]\n",
    "        pass\n",
    "    \n",
    "    if not no_contours:\n",
    "        if scale_from ==0:\n",
    "            _ti=\"Difference between two contours, Specific scale\"\n",
    "            fig = draw_contour(_x, _z, difference_matrix, levels=custom_levels, \n",
    "                         plot_title=_ti,\n",
    "                         x_step=x_step, z_step=z_step, \n",
    "                         mirror_x=mirror_x, mirror_z=mirror_z, \n",
    "                         return_figure_object=return_figure_object);\n",
    "        else:\n",
    "            _ti=\"Difference between two contours, Normal scale\"\n",
    "            fig = draw_contour(_x, _z, difference_matrix, levels=_levels, \n",
    "                         plot_title=_ti,\n",
    "                         x_step=x_step, z_step=z_step, \n",
    "                         mirror_x=mirror_x, mirror_z=mirror_z,\n",
    "                         return_figure_object=return_figure_object);\n",
    "    if not return_calculations and return_figure_object:\n",
    "        return fig\n",
    "    \n",
    "    if calculate_volume_percent:\n",
    "        base_array = _m\n",
    "        base_volumes = integrate_volume(_x[0], _z[:,0], base_array, \n",
    "                                get_average=calculate_average, \n",
    "                                separate_negatives=separate_negatives)\n",
    "        \n",
    "        diff_volumes = integrate_volume(_x[0], _z[:,0], difference_matrix, \n",
    "                                get_average=calculate_average, \n",
    "                                separate_negatives=separate_negatives)\n",
    "#         print (base_volumes, diff_volumes,'\\n')\n",
    "        if isinstance(diff_volumes,tuple):\n",
    "            prc_vol= list(diff_volumes)\n",
    "        else: # Numpy array\n",
    "            prc_vol = diff_volumes.tolist()\n",
    "        \n",
    "        if calculate_average & separate_negatives:\n",
    "            # the resturns will be in the form: ((Vol, Th, A), (Vol, Th, A), \n",
    "            #                                   (Vol, Th, A))\n",
    "            # where the groups are for +ve, -ve, and totals\n",
    "            for res in range(3):\n",
    "                prc_vol.append(diff_volumes[res][0] / base_volumes[2][0])\n",
    "                pass\n",
    "#             prc_vol[-2] = prc_vol[-1]-prc_vol[-3]\n",
    "        elif calculate_average & (not separate_negatives):\n",
    "            # the resturns will be in the form: (Vol, Th, A)\n",
    "            prc_vol.append(diff_volumes[0] / base_volumes[0])\n",
    "            pass\n",
    "        elif (not calculate_average) & separate_negatives:\n",
    "            # the resturns will be in the form: (Vol, Vol, Vol)\n",
    "            # where the groups are for +ve, -ve, and totals\n",
    "            # volume ratio\n",
    "            for res in range(3):\n",
    "                prc_vol.append(diff_volumes[res] / base_volumes[res])\n",
    "                pass\n",
    "        else: #(not calculate_average) & (not separate_negatives)\n",
    "            # the resturns will be in the form: Vol\n",
    "            prc_vol=(prc_vol, diff_volumes / base_volumes)\n",
    "            pass\n",
    "        \n",
    "        if return_figure_object:\n",
    "            return tuple(prc_vol),fig\n",
    "        else:\n",
    "            return tuple(prc_vol)\n",
    "                           \n",
    "                           \n",
    "            \n",
    "    if calculate_volume:\n",
    "        Lx, Lz = _x[0], _z[:,0]\n",
    "        calcs= integrate_volume(Lx, Lz, difference_matrix, \n",
    "                                get_average=calculate_average, \n",
    "                                separate_negatives=separate_negatives)\n",
    "        if return_figure_object:\n",
    "            return calcs, fig\n",
    "        else:\n",
    "            return calcs\n",
    "    \n",
    "    # If both calculate_volume=False, and no_contours=False, \n",
    "    # it will return None with a warning\n",
    "    if no_contours and not calculate_volume:\n",
    "        print (\"Warning, both calculate_volume and no_contours are set to False\")\n",
    "        print (\"         Please set at least one argument to True.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_for_grid(arr1, arr2, scale_from=0,\n",
    "                        grid=(7, 5)):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # To draw diffecence between two contour maps\n",
    "    if scale_from ==2:\n",
    "        _x, _z, _m , _levels= arr2\n",
    "    else:\n",
    "        _x, _z, _m , _levels= arr1\n",
    "        pass\n",
    "    \n",
    "    # identify grid limits\n",
    "    g_x, g_z = grid\n",
    "    l_x, l_z = _x.shape[0],_x.shape[1]\n",
    "    # get quotient and remainder of each dimension\n",
    "    n_x, n_z = l_x // g_x, l_z // g_z\n",
    "    r_x, r_z = l_x % g_x, l_z % g_z\n",
    "    #\n",
    "    lst_x, lst_z= [[0, n_x] for _ in range (g_x)], [[0, n_z] for _ in range (g_z)]\n",
    "    #determining initiation and ending of the grid\n",
    "    x_i, x_e, z_i, z_e = r_x // 2, r_x // 2, r_z // 2, r_z // 2\n",
    "    x_i += r_x % 2\n",
    "    z_i += r_z % 2\n",
    "    lst_x[0][1] += x_i + 1\n",
    "    lst_x[-1][1] = l_x +1\n",
    "    lst_z[0][1] += z_i + 1\n",
    "    lst_z[-1][1] = l_z + 1\n",
    "    for i in range(1, g_x):\n",
    "        lst_x[i][0]=lst_x[i-1][1]\n",
    "        lst_x[i][1]=lst_x[i][0] + n_x + 1\n",
    "    for i in range(1, g_z):\n",
    "        lst_z[i][0]=lst_z[i-1][1]\n",
    "        lst_z[i][1]=lst_z[i][0] + n_z + 1\n",
    "\n",
    "    results=[]\n",
    "    for j, x_g in enumerate(lst_x):\n",
    "        x_gi, x_ge = x_g\n",
    "        for k, z_g in enumerate(lst_z):\n",
    "            z_gi, z_ge = z_g\n",
    "            s_arr1=[0,0,0,0]\n",
    "            s_arr2=[0,0,0,0]\n",
    "            for i in range(3):\n",
    "                s_arr1[i] = arr1[i][x_gi:x_ge:,z_gi:z_ge]\n",
    "                s_arr2[i] = arr2[i][x_gi:x_ge:,z_gi:z_ge]\n",
    "            s_arr2[3] = arr2[3]\n",
    "            s_arr1[3] = arr1[3]\n",
    "            temp_results1 = draw_difference(s_arr1, s_arr2, calculate_volume=True, \n",
    "                            scale_from=scale_from,\n",
    "                            custom_levels=get_legend_range(0, 0.2),\n",
    "                            calculate_average=True, no_contours=True, \n",
    "                            separate_negatives=True, \n",
    "                            calculate_volume_percent=True)\n",
    "            tr1= temp_results1\n",
    "            temp_results2 = (j, k, s_arr1[0].mean(), s_arr1[1].mean(),\n",
    "                             len(s_arr1[2]), np.nanmean(s_arr1[2]), \n",
    "                             np.nanmin(s_arr1[2]), np.nanmax(s_arr1[2]), \n",
    "                             np.nanstd(s_arr1[2]),  \n",
    "                             tr1[0][2], tr1[0][0], tr1[0][1], \n",
    "                             tr1[1][0], tr1[1][1], tr1[2][0], tr1[2][1], \n",
    "                             tr1[3]*100., tr1[4]*100., tr1[5]*100.) \n",
    "            \n",
    "\n",
    "            results.append(temp_results2)\n",
    "    results_head=['x_cord', 'z_cord', 'x_average', 'z_average', \n",
    "                  'm_count', 'm_average', 'm_min', 'm_max', 'm_std', \n",
    "                  'element_area', 'dif_vol_positive', 'dif_avg_positive', \n",
    "                  'dif_vol_negative', 'dif_avg_negative', \n",
    "                  'dif_vol_all', 'dif_avg_all', 'pos_vol_ratio%', 'neg_vol_ratio%',\n",
    "                  'full_vol_ratio%']\n",
    "    df_vol_results = pd.DataFrame.from_records(results, columns=results_head)\n",
    "    return df_vol_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
