{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the rest of HYDRUS files [Stage 2]\n",
    "![The project files](../Assets/Project_files_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:11:24.343666Z",
     "start_time": "2019-11-27T10:11:21.168158Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from NesrHydrusAnalyst import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:11:24.362616Z",
     "start_time": "2019-11-27T10:11:24.359624Z"
    }
   },
   "outputs": [],
   "source": [
    "src = '../Datasets/H3D2_SandDitch0011'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unreadable files\n",
    "Encrypted files that are converted to text elswhere\n",
    "1. `h.out`\n",
    "2. `Q.out`\n",
    "3. `v.out`\n",
    "3. `th.out`\n",
    "4. `MESHTRIA.000`\n",
    "4. `DOMAIN.IN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading previous implemented files\n",
    "### Reading the _mesh files_\n",
    "1. `H.TXT`\n",
    "2. `V.TXT`\n",
    "3. `TH.TXT`\n",
    "4. `MESHTRIA.TXT`\n",
    "### Spread-info files\n",
    "\n",
    "1. `Cum_Q.out`\n",
    "1. `h_Mean.out`\n",
    "1. `v_Mean.out`\n",
    "5. `Run_Inf.out`\n",
    "### the _information files_\n",
    "1. `A_Level.out`\n",
    "2. `ATMOSPH.IN`\n",
    "3. `Balance.out`\n",
    "4. `DIMENSIO.IN`\n",
    "5. `Run_Inf.out` (Repeated)\n",
    "6. `SELECTOR.IN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files to be implemented here\n",
    "\n",
    "\n",
    "### Flux-info files\n",
    "\n",
    "1. `Boundary.out`\n",
    "1. `BOUNDARY.IN`\n",
    "1. `Check.out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:14:57.600491Z",
     "start_time": "2019-11-27T10:14:57.589520Z"
    }
   },
   "outputs": [],
   "source": [
    "folder =src\n",
    "\n",
    "# def read_boundary_data(folder='Current', save_to_csv=True,\n",
    "#                      read_velocities=False):\n",
    "#     '''\n",
    "#     A function to read both Theat and H files from HYDRUS outputs, \n",
    "#         then to:\n",
    "#             1- return one dataframe contains both data in a decent format.\n",
    "#             2- save this output to a CSV file (optional, True by default)\n",
    "#     Input:\n",
    "#         The name of the main folder (leave balank for the current folder)\n",
    "#         The option to save_to csv, default =True (Boolean)\n",
    "#     '''\n",
    "\n",
    "# Specify the source folder\n",
    "if folder == 'Current':\n",
    "    read_dir = os.getcwd()\n",
    "else:\n",
    "    read_dir = folder\n",
    "\n",
    "\n",
    "\n",
    "# Finding number of nodes in the file\n",
    "mesh_file = os.path.join(read_dir, 'BOUNDARY.IN')\n",
    "# num_cells = np.array(linecache.getline(mesh_file, 6).split(), int)#[0]\n",
    "linecache.getline(mesh_file, 6).split()\n",
    "# # Define dataframe titles\n",
    "# titles = ['n', 'x', 'y', 'z']\n",
    "# # Define a list of coordinates\n",
    "# full_data = [[0, 0, 0, 0]]\n",
    "# # Set a loop to geather all coordinates from MESHTRIA.TXT file\n",
    "# for i in range(8, num_cells + 8):\n",
    "#     full_data.append(\n",
    "#         np.array(linecache.getline(mesh_file, i).split(), float))\n",
    "# # Convert the list to numpy array then to a dataframe\n",
    "# coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:40:09.461740Z",
     "start_time": "2019-11-27T10:40:09.449775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,\n",
       " 10,\n",
       " 61,\n",
       " ['1',\n",
       "  '8',\n",
       "  '9',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '20',\n",
       "  '21',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '119',\n",
       "  '122',\n",
       "  '124',\n",
       "  '126',\n",
       "  '128',\n",
       "  '130',\n",
       "  '132',\n",
       "  '134',\n",
       "  '136',\n",
       "  '138',\n",
       "  '140',\n",
       "  '142',\n",
       "  '144',\n",
       "  '146',\n",
       "  '147',\n",
       "  '148',\n",
       "  '149',\n",
       "  '150',\n",
       "  '152',\n",
       "  '154',\n",
       "  '156',\n",
       "  '158',\n",
       "  '160',\n",
       "  '162',\n",
       "  '164',\n",
       "  '166',\n",
       "  '168',\n",
       "  '170',\n",
       "  '172',\n",
       "  '174',\n",
       "  '176',\n",
       "  '629',\n",
       "  '632',\n",
       "  '634',\n",
       "  '636',\n",
       "  '638',\n",
       "  '640',\n",
       "  '642',\n",
       "  '644',\n",
       "  '646',\n",
       "  '648',\n",
       "  '650',\n",
       "  '652',\n",
       "  '654',\n",
       "  '656',\n",
       "  '657',\n",
       "  '658',\n",
       "  '659',\n",
       "  '660',\n",
       "  '662',\n",
       "  '664',\n",
       "  '666',\n",
       "  '668',\n",
       "  '670',\n",
       "  '672',\n",
       "  '674',\n",
       "  '676',\n",
       "  '678',\n",
       "  '680',\n",
       "  '682',\n",
       "  '684',\n",
       "  '686',\n",
       "  '1021',\n",
       "  '1022',\n",
       "  '1023',\n",
       "  '1024',\n",
       "  '1025',\n",
       "  '1026',\n",
       "  '1027',\n",
       "  '1028',\n",
       "  '1029',\n",
       "  '1030',\n",
       "  '1031',\n",
       "  '1032',\n",
       "  '1033',\n",
       "  '1034',\n",
       "  '1035',\n",
       "  '1036',\n",
       "  '1037',\n",
       "  '1038',\n",
       "  '1039',\n",
       "  '1040',\n",
       "  '1041',\n",
       "  '1042',\n",
       "  '1043',\n",
       "  '1044',\n",
       "  '2437',\n",
       "  '2438',\n",
       "  '2439',\n",
       "  '2440',\n",
       "  '2441',\n",
       "  '2442',\n",
       "  '2443',\n",
       "  '2444',\n",
       "  '2445',\n",
       "  '2446',\n",
       "  '2447',\n",
       "  '2448',\n",
       "  '2449',\n",
       "  '2450',\n",
       "  '2451',\n",
       "  '2452',\n",
       "  '2453',\n",
       "  '2454',\n",
       "  '2455',\n",
       "  '2456',\n",
       "  '2457',\n",
       "  '2458',\n",
       "  '2459',\n",
       "  '2460',\n",
       "  '2761',\n",
       "  '2762',\n",
       "  '2763',\n",
       "  '2764',\n",
       "  '2765',\n",
       "  '2766',\n",
       "  '2767',\n",
       "  '2768',\n",
       "  '2769',\n",
       "  '2770',\n",
       "  '2771',\n",
       "  '2772',\n",
       "  '2773',\n",
       "  '2774',\n",
       "  '2775',\n",
       "  '2776',\n",
       "  '2777',\n",
       "  '2778',\n",
       "  '2779',\n",
       "  '2780',\n",
       "  '2781',\n",
       "  '2782',\n",
       "  '2783',\n",
       "  '2784',\n",
       "  '2785',\n",
       "  '2786',\n",
       "  '2787',\n",
       "  '2788',\n",
       "  '2789',\n",
       "  '2790',\n",
       "  '2791',\n",
       "  '2792',\n",
       "  '2793',\n",
       "  '2794',\n",
       "  '2795',\n",
       "  '2796',\n",
       "  '2797',\n",
       "  '2798',\n",
       "  '2799',\n",
       "  '2800',\n",
       "  '2801',\n",
       "  '2802',\n",
       "  '2803',\n",
       "  '2804',\n",
       "  '2805',\n",
       "  '2806',\n",
       "  '2807',\n",
       "  '2808',\n",
       "  '2809',\n",
       "  '2810',\n",
       "  '2811',\n",
       "  '2812',\n",
       "  '2813',\n",
       "  '2814',\n",
       "  '2815',\n",
       "  '2816',\n",
       "  '2817',\n",
       "  '2818',\n",
       "  '2819',\n",
       "  '2820',\n",
       "  '2821',\n",
       "  '2822',\n",
       "  '2823',\n",
       "  '2824',\n",
       "  '2825',\n",
       "  '2826',\n",
       "  '2827',\n",
       "  '2828',\n",
       "  '2829',\n",
       "  '2830',\n",
       "  '2831',\n",
       "  '2832',\n",
       "  '2833',\n",
       "  '2834',\n",
       "  '2835',\n",
       "  '2836',\n",
       "  '2837',\n",
       "  '2838',\n",
       "  '2839',\n",
       "  '2840',\n",
       "  '2841',\n",
       "  '2842',\n",
       "  '2843',\n",
       "  '2844',\n",
       "  '2845',\n",
       "  '2846',\n",
       "  '2847',\n",
       "  '2848',\n",
       "  '2849',\n",
       "  '2850',\n",
       "  '2851',\n",
       "  '2852',\n",
       "  '2853',\n",
       "  '2854',\n",
       "  '2855',\n",
       "  '2856',\n",
       "  '2857',\n",
       "  '2858',\n",
       "  '2859',\n",
       "  '2860',\n",
       "  '2861',\n",
       "  '2862',\n",
       "  '2863',\n",
       "  '2864',\n",
       "  '2865',\n",
       "  '2866',\n",
       "  '2867',\n",
       "  '2868',\n",
       "  '2869',\n",
       "  '2870',\n",
       "  '2871',\n",
       "  '2872',\n",
       "  '2873',\n",
       "  '2874',\n",
       "  '2875',\n",
       "  '2876',\n",
       "  '2877',\n",
       "  '2878',\n",
       "  '2879',\n",
       "  '2880',\n",
       "  '2881',\n",
       "  '2882',\n",
       "  '2883',\n",
       "  '2884',\n",
       "  '2885',\n",
       "  '2886',\n",
       "  '2887',\n",
       "  '2888',\n",
       "  '2889',\n",
       "  '2890',\n",
       "  '2891',\n",
       "  '2892',\n",
       "  '2893',\n",
       "  '2894',\n",
       "  '2895',\n",
       "  '2896',\n",
       "  '2897',\n",
       "  '2898',\n",
       "  '2899',\n",
       "  '2900',\n",
       "  '2901',\n",
       "  '2902',\n",
       "  '2903',\n",
       "  '2904',\n",
       "  '2905',\n",
       "  '2906',\n",
       "  '2907',\n",
       "  '2908',\n",
       "  '2909',\n",
       "  '2910',\n",
       "  '2911',\n",
       "  '2912',\n",
       "  '2913',\n",
       "  '2914',\n",
       "  '2915',\n",
       "  '2916',\n",
       "  '2917',\n",
       "  '2918',\n",
       "  '2919',\n",
       "  '2920',\n",
       "  '2921',\n",
       "  '2922',\n",
       "  '2923',\n",
       "  '2924',\n",
       "  '2925',\n",
       "  '2926',\n",
       "  '2927',\n",
       "  '2928',\n",
       "  '2929',\n",
       "  '2930',\n",
       "  '2931',\n",
       "  '2932',\n",
       "  '2933',\n",
       "  '2934',\n",
       "  '2935',\n",
       "  '2936',\n",
       "  '2937',\n",
       "  '2938',\n",
       "  '2939',\n",
       "  '2940',\n",
       "  '2941',\n",
       "  '2942',\n",
       "  '2943',\n",
       "  '2944',\n",
       "  '2945',\n",
       "  '2946',\n",
       "  '2947',\n",
       "  '2948',\n",
       "  '2949',\n",
       "  '2950',\n",
       "  '2951',\n",
       "  '2952',\n",
       "  '2953',\n",
       "  '2954',\n",
       "  '2955',\n",
       "  '2956',\n",
       "  '2957',\n",
       "  '2958',\n",
       "  '2959',\n",
       "  '2960',\n",
       "  '2961',\n",
       "  '2962',\n",
       "  '2963',\n",
       "  '2964',\n",
       "  '2965',\n",
       "  '2966',\n",
       "  '2967',\n",
       "  '2968',\n",
       "  '2969',\n",
       "  '2970',\n",
       "  '2971',\n",
       "  '2972',\n",
       "  '2973',\n",
       "  '2974',\n",
       "  '2975',\n",
       "  '2976',\n",
       "  '2977',\n",
       "  '2978',\n",
       "  '2979',\n",
       "  '2980',\n",
       "  '2981',\n",
       "  '2982',\n",
       "  '2983',\n",
       "  '2984',\n",
       "  '2985',\n",
       "  '2986',\n",
       "  '2987',\n",
       "  '2988',\n",
       "  '2989',\n",
       "  '2990',\n",
       "  '2991',\n",
       "  '2992',\n",
       "  '2993',\n",
       "  '2994',\n",
       "  '2995',\n",
       "  '2996',\n",
       "  '2997',\n",
       "  '2998',\n",
       "  '2999',\n",
       "  '3000',\n",
       "  '3001',\n",
       "  '3002',\n",
       "  '3003',\n",
       "  '3004',\n",
       "  '3005',\n",
       "  '3006',\n",
       "  '3007',\n",
       "  '3008',\n",
       "  '3009',\n",
       "  '3010',\n",
       "  '3011',\n",
       "  '3012',\n",
       "  '3013',\n",
       "  '3014',\n",
       "  '3015',\n",
       "  '3016',\n",
       "  '3017',\n",
       "  '3018',\n",
       "  '3019',\n",
       "  '3020',\n",
       "  '3021',\n",
       "  '3022',\n",
       "  '3023',\n",
       "  '3024',\n",
       "  '3025',\n",
       "  '3026',\n",
       "  '3027',\n",
       "  '3028',\n",
       "  '3029',\n",
       "  '3030',\n",
       "  '3031',\n",
       "  '3032',\n",
       "  '3033',\n",
       "  '3034',\n",
       "  '3035',\n",
       "  '3036',\n",
       "  '3037',\n",
       "  '3038',\n",
       "  '3039',\n",
       "  '3040',\n",
       "  '3041',\n",
       "  '3042',\n",
       "  '3043',\n",
       "  '3044',\n",
       "  '3045',\n",
       "  '3046',\n",
       "  '3047',\n",
       "  '3048',\n",
       "  '3049',\n",
       "  '3050',\n",
       "  '3051',\n",
       "  '3052',\n",
       "  '3053',\n",
       "  '3054',\n",
       "  '3055',\n",
       "  '3056',\n",
       "  '3057',\n",
       "  '3058',\n",
       "  '3059',\n",
       "  '3060',\n",
       "  '3061',\n",
       "  '3062',\n",
       "  '3063',\n",
       "  '3064',\n",
       "  '3065',\n",
       "  '3066',\n",
       "  '3067',\n",
       "  '3068',\n",
       "  '3069',\n",
       "  '3070',\n",
       "  '3071',\n",
       "  '3072',\n",
       "  '3073',\n",
       "  '3074',\n",
       "  '3075',\n",
       "  '3076',\n",
       "  '3077',\n",
       "  '3078',\n",
       "  '3079',\n",
       "  '3080',\n",
       "  '3081',\n",
       "  '3082',\n",
       "  '3083',\n",
       "  '3084',\n",
       "  '3085',\n",
       "  '3086',\n",
       "  '3087',\n",
       "  '3088',\n",
       "  '3089',\n",
       "  '3090',\n",
       "  '3091',\n",
       "  '3092',\n",
       "  '3093',\n",
       "  '3094',\n",
       "  '3095',\n",
       "  '3096',\n",
       "  '3097',\n",
       "  '3098',\n",
       "  '3099',\n",
       "  '3100',\n",
       "  '3101',\n",
       "  '3102',\n",
       "  '3103',\n",
       "  '3104',\n",
       "  '3105',\n",
       "  '3106',\n",
       "  '3107',\n",
       "  '3108',\n",
       "  '3109',\n",
       "  '3110',\n",
       "  '3111',\n",
       "  '3112',\n",
       "  '3113',\n",
       "  '3114',\n",
       "  '3115',\n",
       "  '3116',\n",
       "  '3117',\n",
       "  '3118',\n",
       "  '3119',\n",
       "  '3120',\n",
       "  '3121',\n",
       "  '3122',\n",
       "  '3123',\n",
       "  '3124',\n",
       "  '3125',\n",
       "  '3126',\n",
       "  '3127',\n",
       "  '3128',\n",
       "  '3129',\n",
       "  '3130',\n",
       "  '3131',\n",
       "  '3132',\n",
       "  '3133',\n",
       "  '3134',\n",
       "  '3135',\n",
       "  '3136',\n",
       "  '3137',\n",
       "  '3138',\n",
       "  '3139',\n",
       "  '3140',\n",
       "  '3141',\n",
       "  '3142',\n",
       "  '3143',\n",
       "  '3144',\n",
       "  '3145',\n",
       "  '3146',\n",
       "  '3147',\n",
       "  '3148'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = src\n",
    "\n",
    "# def read_boundary_data(folder='Current', save_to_csv=True,\n",
    "#                      read_velocities=False):\n",
    "#     '''\n",
    "#     A function to read both Theat and H files from HYDRUS outputs,\n",
    "#         then to:\n",
    "#             1- return one dataframe contains both data in a decent format.\n",
    "#             2- save this output to a CSV file (optional, True by default)\n",
    "#     Input:\n",
    "#         The name of the main folder (leave balank for the current folder)\n",
    "#         The option to save_to csv, default =True (Boolean)\n",
    "#     '''\n",
    "\n",
    "# Specify the source folder\n",
    "if folder == 'Current':\n",
    "    read_dir = os.getcwd()\n",
    "else:\n",
    "    read_dir = folder\n",
    "\n",
    "# Finding number of nodes in the file\n",
    "mesh_file = os.path.join(read_dir, 'BOUNDARY.IN')\n",
    "num_cells = int(linecache.getline(mesh_file, 4).split()[0])\n",
    "# Define dataframe titles\n",
    "titles = ['n', 'srf_area']\n",
    "# Define a list of coordinates\n",
    "points = []\n",
    "# Set a loop to geather all coordinates from MESHTRIA.TXT file\n",
    "start_line = 10\n",
    "nums_per_line = 10\n",
    "num_cells=510\n",
    "num_lines = int(num_cells / nums_per_line)\n",
    "if num_cells % nums_per_line > 0: num_lines += 1\n",
    "for i in range(start_line, num_lines + start_line):\n",
    "    points.extend(linecache.getline(mesh_file, i).split())\n",
    "num_lines , start_line, num_lines + start_line, points\n",
    "#     points.append(np.array(linecache.getline(mesh_file, i).split(), int))\n",
    "# # Convert the list to numpy array then to a dataframe\n",
    "# coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)\n",
    "\n",
    "#     # Print head and tail of the dataframe to ensure correctness\n",
    "#     # pd.concat([coordinates_df.head(),coordinates_df.tail()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:14:57.600491Z",
     "start_time": "2019-11-27T10:14:57.589520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     # -----------------------------#\n",
    "#     # To get data from all files   #\n",
    "#     # -----------------------------#\n",
    "#     def get_data_from_file(filename='TH.TXT', main_caption='Theta'):\n",
    "#         '''\n",
    "#         Function to combine all values of a property to a single dataframe \n",
    "#         inputs:\n",
    "#         filename, the name of the file\n",
    "#         caption, the leading caption of the columns (we will add the portion '_T= xxx')\n",
    "#         where xxx is the timestep\n",
    "#         '''\n",
    "#         # compute number of lines for each timestep\n",
    "#         num_lines = int(math.ceil(num_cells / 10.))\n",
    "#         time_steps_remaining = True  # Flag to see if the loop should continue or not.\n",
    "#         times_df = pd.DataFrame([])  # Empty dataframe\n",
    "#         time_loc_start = 2  # The starting cell of the timestep\n",
    "#         # Check if it is a velocity file\n",
    "#         processing_velocity = (filename[-5:] == 'V.TXT')\n",
    "#         while time_steps_remaining:\n",
    "#             line_t = linecache.getline(filename, time_loc_start).split()\n",
    "#             # Check if it is the start of the timestep, otherwise exit\n",
    "#             if line_t[0] == 'Time':\n",
    "#                 t = int(line_t[2])\n",
    "#                 if processing_velocity:\n",
    "#                     velocity_component = {\n",
    "#                         'first': '1',\n",
    "#                         'second': '2',\n",
    "#                         'third': '3'\n",
    "#                     }[line_t[5].strip()]\n",
    "#                     caption = main_caption + velocity_component\n",
    "#                 else:\n",
    "#                     caption = main_caption\n",
    "#                 # Finding the last line of the timestep\n",
    "#                 tim_loc_end = num_lines + time_loc_start + 2\n",
    "#                 # The starting time is always 0 because steps starts in 1 in HYDRUS\n",
    "#                 time_data = [0]\n",
    "#                 # Create the timestep as one long list\n",
    "#                 for i in range(time_loc_start + 2, tim_loc_end):\n",
    "#                     time_data.extend(linecache.getline(filename, i).split())\n",
    "#                 # Convert the list to DataFrame\n",
    "#                 dft = pd.DataFrame(\n",
    "#                     np.array(time_data, float),\n",
    "#                     columns=['{}_T{}'.format(caption, t)])\n",
    "#                 if len(times_df) == 0:  # If it is the first timestep\n",
    "#                     times_df = dft.copy()\n",
    "#                 else:  # Otherwise (for all other timesteps)\n",
    "#                     times_df = pd.concat([times_df, dft], axis=1)\n",
    "#                 # Change the start to the probable next timestem (if exist)\n",
    "#                 time_loc_start = tim_loc_end + 1\n",
    "#                 time_steps_remaining = True if len(\n",
    "#                     linecache.getline(filename, time_loc_start)) > 0 else False\n",
    "#                 # End IF\n",
    "#         return times_df\n",
    "\n",
    "#     # Set the basic dataframe to the coordinates dataframe, to append to it.\n",
    "#     full_df = coordinates_df\n",
    "#     # Looping through the basic output files then to concatenate them all\n",
    "#     properties = [('TH.TXT', 'Th'), ('H.TXT', 'H'), ('V.TXT', 'V')]\n",
    "#     if not read_velocities:\n",
    "#         properties = properties[:-1]\n",
    "#     for prop in properties:\n",
    "#         file_path = os.path.join(read_dir, prop[0])\n",
    "#         # Check if the file exists\n",
    "#         if os.path.isfile(file_path):\n",
    "#             prop_df = get_data_from_file(file_path, prop[1])\n",
    "#             full_df = pd.concat([full_df, prop_df], axis=1)\n",
    "#         else:\n",
    "#             print(\n",
    "#                 'Warning, the file {} does not exist in the given path'.format(\n",
    "#                     prop[0]))\n",
    "\n",
    "#     # Convert the num column to integer\n",
    "#     full_df[['n']] = full_df[['n']].astype(np.int64)\n",
    "#     # dropping the first row (the zeros row) as it is not necessary\n",
    "#     full_df.drop(0, inplace=True)\n",
    "#     # Saving the resultant dataframe to disk.\n",
    "#     if save_to_csv:\n",
    "#         full_df.to_csv(os.path.join(read_dir, 'nesr_data2.csv'))\n",
    "#     return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
