{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the rest of HYDRUS files [Stage 2]\n",
    "![The project files](../Assets/Project_files_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:11:24.343666Z",
     "start_time": "2019-11-27T10:11:21.168158Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from NesrHydrusAnalyst import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T10:11:24.362616Z",
     "start_time": "2019-11-27T10:11:24.359624Z"
    }
   },
   "outputs": [],
   "source": [
    "src = '../Datasets/H3D2_SandDitch0011'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unreadable files\n",
    "Encrypted files that are converted to text elswhere\n",
    "1. `h.out`\n",
    "2. `Q.out`\n",
    "3. `v.out`\n",
    "3. `th.out`\n",
    "4. `MESHTRIA.000`\n",
    "4. `DOMAIN.IN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading previous implemented files\n",
    "### Reading the _mesh files_\n",
    "1. `H.TXT`\n",
    "2. `V.TXT`\n",
    "3. `TH.TXT`\n",
    "4. `MESHTRIA.TXT`\n",
    "### Spread-info files\n",
    "\n",
    "1. `Cum_Q.out`\n",
    "1. `h_Mean.out`\n",
    "1. `v_Mean.out`\n",
    "5. `Run_Inf.out`\n",
    "### the _information files_\n",
    "1. `A_Level.out`\n",
    "2. `ATMOSPH.IN`\n",
    "3. `Balance.out`\n",
    "4. `DIMENSIO.IN`\n",
    "5. `Run_Inf.out` (Repeated)\n",
    "6. `SELECTOR.IN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files to be implemented here\n",
    "\n",
    "\n",
    "### Flux-info files\n",
    "\n",
    "1. `Boundary.out`\n",
    "1. `BOUNDARY.IN`\n",
    "1. `Check.out`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def read_hydrus_data(folder='Current', save_to_csv=True,\n",
    "#                      read_velocities=False):\n",
    "#     '''\n",
    "#     A function to read both Theat and H files from HYDRUS outputs, \n",
    "#         then to:\n",
    "#             1- return one dataframe contains both data in a decent format.\n",
    "#             2- save this output to a CSV file (optional, True by default)\n",
    "#     Input:\n",
    "#         The name of the main folder (leave balank for the current folder)\n",
    "#         The option to save_to csv, default =True (Boolean)\n",
    "#     '''\n",
    "#     # Specify the source folder\n",
    "#     if folder == 'Current':\n",
    "#         read_dir = os.getcwd()\n",
    "#     else:\n",
    "#         read_dir = folder\n",
    "\n",
    "#     # Finding number of nodes in the file\n",
    "#     mesh_file = os.path.join(read_dir, 'MESHTRIA.TXT')\n",
    "#     num_cells = np.array(linecache.getline(mesh_file, 6).split(), int)[0]\n",
    "#     # Define dataframe titles\n",
    "#     titles = ['n', 'x', 'y', 'z']\n",
    "#     # Define a list of coordinates\n",
    "#     full_data = [[0, 0, 0, 0]]\n",
    "#     # Set a loop to geather all coordinates from MESHTRIA.TXT file\n",
    "#     for i in range(8, num_cells + 8):\n",
    "#         full_data.append(\n",
    "#             np.array(linecache.getline(mesh_file, i).split(), float))\n",
    "#     # Convert the list to numpy array then to a dataframe\n",
    "#     coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)\n",
    "\n",
    "#     # Print head and tail of the dataframe to ensure correctness\n",
    "#     # pd.concat([coordinates_df.head(),coordinates_df.tail()])\n",
    "\n",
    "#     # -----------------------------#\n",
    "#     # To get data from all files   #\n",
    "#     # -----------------------------#\n",
    "#     def get_data_from_file(filename='TH.TXT', main_caption='Theta'):\n",
    "#         '''\n",
    "#         Function to combine all values of a property to a single dataframe \n",
    "#         inputs:\n",
    "#         filename, the name of the file\n",
    "#         caption, the leading caption of the columns (we will add the portion '_T= xxx')\n",
    "#         where xxx is the timestep\n",
    "#         '''\n",
    "#         # compute number of lines for each timestep\n",
    "#         num_lines = int(math.ceil(num_cells / 10.))\n",
    "#         time_steps_remaining = True  # Flag to see if the loop should continue or not.\n",
    "#         times_df = pd.DataFrame([])  # Empty dataframe\n",
    "#         time_loc_start = 2  # The starting cell of the timestep\n",
    "#         # Check if it is a velocity file\n",
    "#         processing_velocity = (filename[-5:] == 'V.TXT')\n",
    "#         while time_steps_remaining:\n",
    "#             line_t = linecache.getline(filename, time_loc_start).split()\n",
    "#             # Check if it is the start of the timestep, otherwise exit\n",
    "#             if line_t[0] == 'Time':\n",
    "#                 t = int(line_t[2])\n",
    "#                 if processing_velocity:\n",
    "#                     velocity_component = {\n",
    "#                         'first': '1',\n",
    "#                         'second': '2',\n",
    "#                         'third': '3'\n",
    "#                     }[line_t[5].strip()]\n",
    "#                     caption = main_caption + velocity_component\n",
    "#                 else:\n",
    "#                     caption = main_caption\n",
    "#                 # Finding the last line of the timestep\n",
    "#                 tim_loc_end = num_lines + time_loc_start + 2\n",
    "#                 # The starting time is always 0 because steps starts in 1 in HYDRUS\n",
    "#                 time_data = [0]\n",
    "#                 # Create the timestep as one long list\n",
    "#                 for i in range(time_loc_start + 2, tim_loc_end):\n",
    "#                     time_data.extend(linecache.getline(filename, i).split())\n",
    "#                 # Convert the list to DataFrame\n",
    "#                 dft = pd.DataFrame(\n",
    "#                     np.array(time_data, float),\n",
    "#                     columns=['{}_T{}'.format(caption, t)])\n",
    "#                 if len(times_df) == 0:  # If it is the first timestep\n",
    "#                     times_df = dft.copy()\n",
    "#                 else:  # Otherwise (for all other timesteps)\n",
    "#                     times_df = pd.concat([times_df, dft], axis=1)\n",
    "#                 # Change the start to the probable next timestem (if exist)\n",
    "#                 time_loc_start = tim_loc_end + 1\n",
    "#                 time_steps_remaining = True if len(\n",
    "#                     linecache.getline(filename, time_loc_start)) > 0 else False\n",
    "#                 # End IF\n",
    "#         return times_df\n",
    "\n",
    "#     # Set the basic dataframe to the coordinates dataframe, to append to it.\n",
    "#     full_df = coordinates_df\n",
    "#     # Looping through the basic output files then to concatenate them all\n",
    "#     properties = [('TH.TXT', 'Th'), ('H.TXT', 'H'), ('V.TXT', 'V')]\n",
    "#     if not read_velocities:\n",
    "#         properties = properties[:-1]\n",
    "#     for prop in properties:\n",
    "#         file_path = os.path.join(read_dir, prop[0])\n",
    "#         # Check if the file exists\n",
    "#         if os.path.isfile(file_path):\n",
    "#             prop_df = get_data_from_file(file_path, prop[1])\n",
    "#             full_df = pd.concat([full_df, prop_df], axis=1)\n",
    "#         else:\n",
    "#             print(\n",
    "#                 'Warning, the file {} does not exist in the given path'.format(\n",
    "#                     prop[0]))\n",
    "\n",
    "#     # Convert the num column to integer\n",
    "#     full_df[['n']] = full_df[['n']].astype(np.int64)\n",
    "#     # dropping the first row (the zeros row) as it is not necessary\n",
    "#     full_df.drop(0, inplace=True)\n",
    "#     # Saving the resultant dataframe to disk.\n",
    "#     if save_to_csv:\n",
    "#         full_df.to_csv(os.path.join(read_dir, 'nesr_data2.csv'))\n",
    "#     return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the `BOUNDARY.IN` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:36:50.899082Z",
     "start_time": "2019-11-27T11:36:50.893099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['518', '0', 'f', 't', 'f', 'f']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder =src\n",
    "\n",
    "# def read_boundary_data(folder='Current', save_to_csv=True,\n",
    "#                      read_velocities=False):\n",
    "#     '''\n",
    "#     A function to read both Theat and H files from HYDRUS outputs, \n",
    "#         then to:\n",
    "#             1- return one dataframe contains both data in a decent format.\n",
    "#             2- save this output to a CSV file (optional, True by default)\n",
    "#     Input:\n",
    "#         The name of the main folder (leave balank for the current folder)\n",
    "#         The option to save_to csv, default =True (Boolean)\n",
    "#     '''\n",
    "\n",
    "# Specify the source folder\n",
    "if folder == 'Current':\n",
    "    read_dir = os.getcwd()\n",
    "else:\n",
    "    read_dir = folder\n",
    "\n",
    "\n",
    "\n",
    "# Finding number of nodes in the file\n",
    "mesh_file = os.path.join(read_dir, 'BOUNDARY.IN')\n",
    "# num_cells = np.array(linecache.getline(mesh_file, 6).split(), int)#[0]\n",
    "linecache.getline(mesh_file, 4).split()\n",
    "# # Define dataframe titles\n",
    "# titles = ['n', 'x', 'y', 'z']\n",
    "# # Define a list of coordinates\n",
    "# full_data = [[0, 0, 0, 0]]\n",
    "# # Set a loop to geather all coordinates from MESHTRIA.TXT file\n",
    "# for i in range(8, num_cells + 8):\n",
    "#     full_data.append(\n",
    "#         np.array(linecache.getline(mesh_file, i).split(), float))\n",
    "# # Convert the list to numpy array then to a dataframe\n",
    "# coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:32:18.731709Z",
     "start_time": "2019-11-27T11:32:18.716750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>surface_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.040982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.762819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.275030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.512820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>3152</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3153</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>3154</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>3155</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>3156</td>\n",
       "      <td>1.538460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n  surface_area\n",
       "0       1      0.020491\n",
       "1       8      0.040982\n",
       "2       9      0.762819\n",
       "3      11      1.275030\n",
       "4      12      0.512820\n",
       "..    ...           ...\n",
       "513  3152      1.538460\n",
       "514  3153      1.538460\n",
       "515  3154      1.538460\n",
       "516  3155      1.538460\n",
       "517  3156      1.538460\n",
       "\n",
       "[518 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = src\n",
    "\n",
    "# def read_boundary_data(folder='Current', save_to_csv=True,\n",
    "#                      read_velocities=False):\n",
    "#     '''\n",
    "#     A function to read both Theat and H files from HYDRUS outputs,\n",
    "#         then to:\n",
    "#             1- return one dataframe contains both data in a decent format.\n",
    "#             2- save this output to a CSV file (optional, True by default)\n",
    "#     Input:\n",
    "#         The name of the main folder (leave balank for the current folder)\n",
    "#         The option to save_to csv, default =True (Boolean)\n",
    "#     '''\n",
    "\n",
    "# Specify the source folder\n",
    "if folder == 'Current':\n",
    "    read_dir = os.getcwd()\n",
    "else:\n",
    "    read_dir = folder\n",
    "\n",
    "# Finding number of nodes in the file\n",
    "mesh_file = os.path.join(read_dir, 'BOUNDARY.IN')\n",
    "num_cells = int(linecache.getline(mesh_file, 4).split()[0])\n",
    "# Define dataframe titles\n",
    "titles = ['n', 'surface_area']\n",
    "\n",
    "\n",
    "def get_num_lines(num_cells, nums_per_line=10):\n",
    "    num_lines = int(num_cells / nums_per_line)\n",
    "    if num_cells % nums_per_line > 0: num_lines += 1\n",
    "    return num_lines\n",
    "\n",
    "\n",
    "def read_snakey_list(file_name, start_line, end_line, data_type=float):\n",
    "    '''\n",
    "    Reading a list of numbers thar are stored in a text file, where\n",
    "    there are `numbers_count` numbers, stored as `nums_per_line` numbers \n",
    "    per line, the starting position of first occurence of numbers is at\n",
    "    `start_line` line number\n",
    "    returns a numpy array of the data with the `data_type` given\n",
    "    '''\n",
    "    points = []\n",
    "    for i in range(start_line, end_line):\n",
    "        points.extend(linecache.getline(file_name, i).split())\n",
    "    return np.array(points, data_type)\n",
    "\n",
    "\n",
    "num_lines = get_num_lines(num_cells, nums_per_line)\n",
    "\n",
    "first_line = 10\n",
    "end_line = first_line + num_lines\n",
    "points = read_snakey_list(mesh_file, first_line, end_line, data_type=int)\n",
    "\n",
    "first_line = end_line + 1\n",
    "end_line = first_line + num_lines\n",
    "areas = read_snakey_list(mesh_file, first_line, end_line)\n",
    "data = np.array([points, areas]).T\n",
    "data_in = pd.DataFrame(\n",
    "    data, columns=titles).astype({\n",
    "        \"n\": int,\n",
    "        \"surface_area\": float\n",
    "    })\n",
    "data_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the `get_means_table` function to read timed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:34:05.112961Z",
     "start_time": "2019-11-27T12:34:05.097005Z"
    },
    "code_folding": [
     28,
     57,
     68,
     75,
     79
    ]
   },
   "outputs": [],
   "source": [
    "def get_means_table(filename,\n",
    "                    header_location,\n",
    "                    data_location,\n",
    "                    units_location=None,\n",
    "                    reading_end='end', \n",
    "                    replace_units=True):\n",
    "    '''\n",
    "    Returns a table of adjusted data to numeric analysis\n",
    "    \n",
    "    We have to specify the:\n",
    "    header_location: the line number that contains the headers, \n",
    "    units_location : the line number that contains the units (if None, then\n",
    "                        no units is allowed), \n",
    "    data_location  : the line number that contains the first line of data.\n",
    "    \n",
    "    if reading_end='end', it reads the lines until it finds the word 'end'\n",
    "        (or any other word) at the beginining of the last line (it will \n",
    "        read before the 'end')\n",
    "    if reading_end=integer, then it will read until it reaches the specified \n",
    "        number (inclusive)\n",
    "        \n",
    "    if replace_units=True, it will replace the units by equivalent numbers\n",
    "        according to the following:\n",
    "        'f', 't' >> 0, 1\n",
    "        'mm', 'cm', 'm' >> 0, 1, 2\n",
    "        'sec', 'min', 'hours', 'days', 'years' >> 0, 1, 2, 3, 4\n",
    "        's', 'min', 'h', 'd', 'y' >>  0, 1, 2, 3, 4\n",
    "    \n",
    "    Units will be written after an underscore without any special chars\n",
    "    e.g. velocity: m/s  --> velocity_mps\n",
    "    \n",
    "    # filename = os.path.join(file_path, 'Cum_Q.out')\n",
    "    '''\n",
    "\n",
    "    # Defining some functions\n",
    "    def proper_type(x):\n",
    "        try:\n",
    "            nf = float(x)\n",
    "            ni = float(int(nf))\n",
    "            # print(nf, ni, abs(nf - ni))\n",
    "            if abs(nf - ni) < 0.0000000000001:\n",
    "                return int(ni)\n",
    "            else:\n",
    "                return nf\n",
    "        except:\n",
    "            return x\n",
    "\n",
    "    def replace_text(x):\n",
    "        if x in ('t', 'f'):\n",
    "            # return {'t':1, 'f':0}[x]\n",
    "            return ['f', 't'].index(x)\n",
    "        elif x in ('mm', 'cm', 'm'):\n",
    "            return ['mm', 'cm', 'm'].index(x)\n",
    "        elif x in ('sec', 'min', 'hours', 'days', 'years'):\n",
    "            return ['sec', 'min', 'hours', 'days', 'years'].index(x)\n",
    "        elif x in ('s', 'min', 'h', 'd', 'y'):\n",
    "            return ['s', 'min', 'h', 'd', 'y'].index(x)\n",
    "        else:\n",
    "            return x  # proper_type(x)\n",
    "\n",
    "    def get_line(filename, pos, replace_units=True):\n",
    "        line_feed = linecache.getline(filename, pos).split()\n",
    "#         print(line_feed)\n",
    "        if replace_units:\n",
    "            return list(map(replace_text, line_feed))\n",
    "        else:\n",
    "            return line_feed\n",
    "\n",
    "    def get_word(filename, pos, loc=0):\n",
    "        word = get_line(pos)\n",
    "        if len(word) < 1:\n",
    "            return ''\n",
    "        else:\n",
    "            word = word[loc]\n",
    "        if isinstance(word, str):\n",
    "            return word.strip()\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    def get_num(p1, p2, is2d):\n",
    "        '''\n",
    "        p1, the line of 2D file\n",
    "        p2, the line of 3D file\n",
    "        '''\n",
    "        return {True: p1, False: p2}[is2d]\n",
    "\n",
    "    def adjust_body(replaceable, headers, body):\n",
    "        for _ in range(len(headers) - len(body)):\n",
    "            body.append(replaceable)\n",
    "\n",
    "    def reform_unit(unit, prefix=None):\n",
    "        '''\n",
    "        Functions to add units\n",
    "\n",
    "        '''\n",
    "\n",
    "        def split_letters(word):\n",
    "            return [_ for _ in word]\n",
    "\n",
    "        reformed = ''.join([{\n",
    "            '/': 'p',\n",
    "            '.': '',\n",
    "            '[': '',\n",
    "            ']': ''\n",
    "        }.get(i, i) for i in split_letters(unit)])\n",
    "        if prefix is None:\n",
    "            return reformed\n",
    "        else:\n",
    "            return prefix + reformed\n",
    "\n",
    "    # Defining variables\n",
    "    headers = []\n",
    "    body = []\n",
    "    headers += get_line(filename, header_location, False)\n",
    "#     print(headers)\n",
    "    try:\n",
    "        # If there is any empty columns, remove them\n",
    "        for _ in range(5):\n",
    "            headers.remove('...')\n",
    "    except:\n",
    "        pass\n",
    "#     print(headers)\n",
    "    headers = [_.replace('...', '') for _ in headers]\n",
    "\n",
    "    if units_location is not None:\n",
    "        units = get_line(filename, units_location, replace_units)\n",
    "        units = [reform_unit(_, '_') for _ in units]\n",
    "        headers = [x + y for x, y in zip(headers, units)]\n",
    "    \n",
    "    if type(reading_end)==str: # 'end' for example\n",
    "        # reading to the end of the file\n",
    "        i = data_location\n",
    "        feed = get_line(filename, i, replace_units)\n",
    "        while feed[0] != reading_end:\n",
    "            body.append(feed)\n",
    "            i += 1\n",
    "            feed = get_line(filename, i, replace_units)\n",
    "    else:\n",
    "        for i in range (data_location, int(reading_end) + 1):\n",
    "            body.append(get_line(filename, i, replace_units))\n",
    "\n",
    "    body = np.array(body)\n",
    "    return pd.DataFrame(body, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:34:05.749756Z",
     "start_time": "2019-11-27T12:34:05.732802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_T</th>\n",
       "      <th>CumQAP_L3</th>\n",
       "      <th>CumQRP_L3</th>\n",
       "      <th>CumQA_L3</th>\n",
       "      <th>CumQR_L3</th>\n",
       "      <th>CumQ3_L3</th>\n",
       "      <th>CumQ1_L3</th>\n",
       "      <th>CumQS_L3</th>\n",
       "      <th>CumQ5_L3</th>\n",
       "      <th>CumQ6_L3</th>\n",
       "      <th>CumQ7_L3</th>\n",
       "      <th>CumQ8_L3</th>\n",
       "      <th>CumQ9_L3</th>\n",
       "      <th>CRunOff_L3</th>\n",
       "      <th>cEvapor_L3</th>\n",
       "      <th>cInfiltr_L3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>129.9850</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>-0.240E+04</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.981E+01</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>60.0050</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>-0.240E+04</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.284E-01</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>-0.257E+02</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.369E-02</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time_T  CumQAP_L3  CumQRP_L3   CumQA_L3   CumQR_L3    CumQ3_L3  \\\n",
       "531  129.9850  0.000E+00  0.000E+00  0.000E+00  0.000E+00  -0.240E+04   \n",
       "443   60.0050  0.000E+00  0.000E+00  0.000E+00  0.000E+00  -0.240E+04   \n",
       "61     0.6423  0.000E+00  0.000E+00  0.000E+00  0.000E+00  -0.257E+02   \n",
       "\n",
       "      CumQ1_L3   CumQS_L3   CumQ5_L3   CumQ6_L3   CumQ7_L3   CumQ8_L3  \\\n",
       "531  0.000E+00  0.000E+00  0.000E+00  0.981E+01  0.000E+00  0.000E+00   \n",
       "443  0.000E+00  0.000E+00  0.000E+00  0.284E-01  0.000E+00  0.000E+00   \n",
       "61   0.000E+00  0.000E+00  0.000E+00  0.369E-02  0.000E+00  0.000E+00   \n",
       "\n",
       "      CumQ9_L3 CRunOff_L3 cEvapor_L3 cInfiltr_L3  \n",
       "531  0.000E+00  0.000E+00  0.000E+00   0.000E+00  \n",
       "443  0.000E+00  0.000E+00  0.000E+00   0.000E+00  \n",
       "61   0.000E+00  0.000E+00  0.000E+00   0.000E+00  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test of previous implementation that it still works\n",
    "\n",
    "get_means_table(os.path.join(src, 'Cum_Q.out'), 11, 14, 12).sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T12:34:06.602123Z",
     "start_time": "2019-11-27T12:34:06.585167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>n</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Code</th>\n",
       "      <th>Q</th>\n",
       "      <th>v</th>\n",
       "      <th>h</th>\n",
       "      <th>th</th>\n",
       "      <th>Temp</th>\n",
       "      <th>cumQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>226</td>\n",
       "      <td>2864</td>\n",
       "      <td>11.15</td>\n",
       "      <td>6.15</td>\n",
       "      <td>21.46</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>-27.67</td>\n",
       "      <td>0.083</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.000E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>328</td>\n",
       "      <td>2966</td>\n",
       "      <td>20.14</td>\n",
       "      <td>10.77</td>\n",
       "      <td>21.82</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>-27.79</td>\n",
       "      <td>0.082</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.000E+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>664</td>\n",
       "      <td>29.14</td>\n",
       "      <td>20.00</td>\n",
       "      <td>22.18</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>0.000E+00</td>\n",
       "      <td>-25.55</td>\n",
       "      <td>0.088</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.000E+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       i     n      x      y      z Code          Q          v       h     th  \\\n",
       "225  226  2864  11.15   6.15  21.46   -4  0.000E+00  0.000E+00  -27.67  0.083   \n",
       "327  328  2966  20.14  10.77  21.82   -4  0.000E+00  0.000E+00  -27.79  0.082   \n",
       "62    63   664  29.14  20.00  22.18   -4  0.000E+00  0.000E+00  -25.55  0.088   \n",
       "\n",
       "       Temp       cumQ  \n",
       "225  20.000  0.000E+00  \n",
       "327  20.000  0.000E+00  \n",
       "62   20.000  0.000E+00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test of the new implementation that it works\n",
    "\n",
    "get_means_table(os.path.join(src, 'Boundary.out'), 19, 22, units_location=None,\n",
    "    reading_end=539,replace_units=False).sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T11:46:03.913200Z",
     "start_time": "2019-11-27T11:46:03.904223Z"
    }
   },
   "outputs": [],
   "source": [
    "# folder = src\n",
    "# num_cells = num_cells\n",
    "# # def read_hydrus_data(folder='Current', save_to_csv=True,\n",
    "# #                      read_velocities=False):\n",
    "# #     '''\n",
    "# #     A function to read both Theat and H files from HYDRUS outputs, \n",
    "# #         then to:\n",
    "# #             1- return one dataframe contains both data in a decent format.\n",
    "# #             2- save this output to a CSV file (optional, True by default)\n",
    "# #     Input:\n",
    "# #         The name of the main folder (leave balank for the current folder)\n",
    "# #         The option to save_to csv, default =True (Boolean)\n",
    "# #     '''\n",
    "# # Specify the source folder\n",
    "# if folder == 'Current':\n",
    "#     read_dir = os.getcwd()\n",
    "# else:\n",
    "#     read_dir = folder\n",
    "\n",
    "# # Finding number of nodes in the file\n",
    "# mesh_file = os.path.join(read_dir, 'Boundary.out')\n",
    "# # Define dataframe titles\n",
    "# titles = ['n', 'x', 'y', 'z']\n",
    "# # Define a list of coordinates\n",
    "# full_data = [[0, 0, 0, 0]]\n",
    "# # Set a loop to geather all coordinates from MESHTRIA.TXT file\n",
    "# for i in range(8, num_cells + 8):\n",
    "#     full_data.append(\n",
    "#         np.array(linecache.getline(mesh_file, i).split(), float))\n",
    "# # Convert the list to numpy array then to a dataframe\n",
    "# coordinates_df = pd.DataFrame(np.array(full_data), columns=titles)\n",
    "\n",
    "# # Print head and tail of the dataframe to ensure correctness\n",
    "# # pd.concat([coordinates_df.head(),coordinates_df.tail()])\n",
    "\n",
    "# # -----------------------------#\n",
    "# # To get data from all files   #\n",
    "# # -----------------------------#\n",
    "# def get_data_from_file(filename='TH.TXT', main_caption='Theta'):\n",
    "#     '''\n",
    "#     Function to combine all values of a property to a single dataframe \n",
    "#     inputs:\n",
    "#     filename, the name of the file\n",
    "#     caption, the leading caption of the columns (we will add the portion '_T= xxx')\n",
    "#     where xxx is the timestep\n",
    "#     '''\n",
    "#     # compute number of lines for each timestep\n",
    "#     num_lines = int(math.ceil(num_cells / 10.))\n",
    "#     time_steps_remaining = True  # Flag to see if the loop should continue or not.\n",
    "#     times_df = pd.DataFrame([])  # Empty dataframe\n",
    "#     time_loc_start = 2  # The starting cell of the timestep\n",
    "#     # Check if it is a velocity file\n",
    "#     processing_velocity = (filename[-5:] == 'V.TXT')\n",
    "#     while time_steps_remaining:\n",
    "#         line_t = linecache.getline(filename, time_loc_start).split()\n",
    "#         # Check if it is the start of the timestep, otherwise exit\n",
    "#         if line_t[0] == 'Time':\n",
    "#             t = int(line_t[2])\n",
    "#             if processing_velocity:\n",
    "#                 velocity_component = {\n",
    "#                     'first': '1',\n",
    "#                     'second': '2',\n",
    "#                     'third': '3'\n",
    "#                 }[line_t[5].strip()]\n",
    "#                 caption = main_caption + velocity_component\n",
    "#             else:\n",
    "#                 caption = main_caption\n",
    "#             # Finding the last line of the timestep\n",
    "#             tim_loc_end = num_lines + time_loc_start + 2\n",
    "#             # The starting time is always 0 because steps starts in 1 in HYDRUS\n",
    "#             time_data = [0]\n",
    "#             # Create the timestep as one long list\n",
    "#             for i in range(time_loc_start + 2, tim_loc_end):\n",
    "#                 time_data.extend(linecache.getline(filename, i).split())\n",
    "#             # Convert the list to DataFrame\n",
    "#             dft = pd.DataFrame(\n",
    "#                 np.array(time_data, float),\n",
    "#                 columns=['{}_T{}'.format(caption, t)])\n",
    "#             if len(times_df) == 0:  # If it is the first timestep\n",
    "#                 times_df = dft.copy()\n",
    "#             else:  # Otherwise (for all other timesteps)\n",
    "#                 times_df = pd.concat([times_df, dft], axis=1)\n",
    "#             # Change the start to the probable next timestem (if exist)\n",
    "#             time_loc_start = tim_loc_end + 1\n",
    "#             time_steps_remaining = True if len(\n",
    "#                 linecache.getline(filename, time_loc_start)) > 0 else False\n",
    "#             # End IF\n",
    "#     return times_df\n",
    "\n",
    "# # Set the basic dataframe to the coordinates dataframe, to append to it.\n",
    "# full_df = coordinates_df\n",
    "# # Looping through the basic output files then to concatenate them all\n",
    "# properties = [('TH.TXT', 'Th'), ('H.TXT', 'H'), ('V.TXT', 'V')]\n",
    "# if not read_velocities:\n",
    "#     properties = properties[:-1]\n",
    "# for prop in properties:\n",
    "#     file_path = os.path.join(read_dir, prop[0])\n",
    "#     # Check if the file exists\n",
    "#     if os.path.isfile(file_path):\n",
    "#         prop_df = get_data_from_file(file_path, prop[1])\n",
    "#         full_df = pd.concat([full_df, prop_df], axis=1)\n",
    "#     else:\n",
    "#         print(\n",
    "#             'Warning, the file {} does not exist in the given path'.format(\n",
    "#                 prop[0]))\n",
    "\n",
    "# # Convert the num column to integer\n",
    "# full_df[['n']] = full_df[['n']].astype(np.int64)\n",
    "# # dropping the first row (the zeros row) as it is not necessary\n",
    "# full_df.drop(0, inplace=True)\n",
    "# # Saving the resultant dataframe to disk.\n",
    "# if save_to_csv:\n",
    "#     full_df.to_csv(os.path.join(read_dir, 'nesr_data2.csv'))\n",
    "# return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
